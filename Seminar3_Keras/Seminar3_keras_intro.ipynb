{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 3. Нейронные сети. Tensorflow и Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фреймворки:\n",
    "\n",
    "- <strong>TensorFlow*</strong> — открытая программная библиотека для построения и обучения нейронных сетей, разработанная компанией Google. Основной API для работы с библиотекой реализован для Python. \n",
    "\n",
    "    Также существуют реализации для: R, C Sharp, C++, Haskell, Java, Go, Swift.\n",
    "\n",
    "    https://www.tensorflow.org\n",
    "\n",
    "\n",
    " - <strong>Keras**</strong>  — открытая программная библиотека, представляющая из себя надстройку над библиоткеми Deeplearning4j, TensorFlow и Theano. Является скорее интерфейсом над указанными библиотеками и предоставляет высокоуровневый, более интуитивный набор абстракций, который делает простым формирование нейронных сетей.\n",
    "\n",
    "    Разработана инженером Google – Франсуа Шолле\n",
    "\n",
    "    https://keras.io\n",
    "\n",
    "\n",
    "<strong>Установка</strong>: \n",
    "- pip install tensorflow\n",
    "- pip install keras\n",
    "\n",
    "_____\n",
    "\n",
    "<blockquote>\n",
    "* https://ru.wikipedia.org/wiki/TensorFlow  | **https://ru.wikipedia.org/wiki/Keras \n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План семинара:\n",
    "\n",
    "#### > Основы Keras:\n",
    "1. Инициализация модели и построение слоев нейронной сети\n",
    "2. Назначение гиперпараметров сети\n",
    "3. Обучение и тестирование нейронной сети\n",
    "4. Сохранение и вызов нейронной сети из файла\n",
    "5. Редактирование модели: выделение и встраивание слоев, фиксация весов\n",
    "\n",
    "#### > Построение и обучение пройденных моделей:\n",
    "1. Многослойный перцептрон\n",
    "2. Автоассоциативная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основы Keras\n",
    "\n",
    "### 1. Инициализация модели и построение слоев нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 4)                 16        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "#вариант 1\n",
    "model= keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(4,)),\n",
    "        layers.Dense(2, activation=\"sigmoid\", name=\"layer1\"),\n",
    "        layers.Dense(3, activation=\"sigmoid\", name=\"layer2\"),\n",
    "        layers.Dense(4, name=\"layer3\"),\n",
    "    ],\n",
    "    name=\"MLP_1\"\n",
    ")\n",
    "\n",
    "model.build() #собираем модель (если производится обучение, то build не нужно)\n",
    "model.summary() #вывод таблицы архитектуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 4)                 16        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#вариант 2\n",
    "model = keras.Sequential(name=\"MLP_2\")\n",
    "\n",
    "model.add(keras.Input(shape=(4,)))\n",
    "model.add(layers.Dense(2, activation=\"sigmoid\", name=\"layer1\"))\n",
    "model.add(layers.Dense(3, activation=\"sigmoid\", name=\"layer2\"))\n",
    "model.add(layers.Dense(4, name=\"layer3\"))\n",
    "\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Назначение гиперпараметров сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "#оптимизатор (SGD - стохастический градиентный спуск)\n",
    "opt = keras.optimizers.SGD(learning_rate=0.3)\n",
    "# learning_rate - скорость обучения\n",
    "\n",
    "#функция потерь (среднее кваратическое ошибки)\n",
    "f_loss = losses.MeanSquaredError()\n",
    "\n",
    "#НОВОЕ: метрика - гиперпараметр валидации (accuracy - достигнутая точность)\n",
    "        #под валидацией понимается тестирование в процессе обучения\n",
    "met = ['accuracy']\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,  \n",
    "    loss=f_loss,  \n",
    "    metrics=met, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Обучение и тестирование нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучение\n",
    "\n",
    "#обучающее множество (тут не объявлено)\n",
    "x_train = ...\n",
    "y_train = ...\n",
    "\n",
    "#валидационное множество (можно использовать тестовое)\n",
    "x_test = ...\n",
    "y_test = ...\n",
    "\n",
    "#частота валидации\n",
    "batch_size = 64  #раз в 64 строчки обучающего множества\n",
    "\n",
    "#количество эпох обучения\n",
    "ep = 100\n",
    "ep_start = 0 #эпоха, с которой начинается обучения (если дообучать обученную сеть)\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x=x_train\n",
    "    y=y_train\n",
    "    batch_size=batch_size,\n",
    "    epochs=ep,\n",
    "    validation_data=(x_test,y_test)\n",
    "    initial_epoch=ep_start\n",
    "    steps_per_epoch=None, #если необходимо обучать не по всему обучающему множеству\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Тестирование\n",
    "model.evaluate(x=x_test, y=y_test)\n",
    "\n",
    "#Использование обученной нейронной сети\n",
    "y=model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Сохранение и вызов нейронной сети из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение обученной нейронной сети\n",
    "model.save(\"models/my_model.h5\") #сохраняет в формат h5\n",
    "model.save(\"models/my_model\") #сохраняет в виде папки\n",
    "\n",
    "#Вызов нейронной сети из файла\n",
    "model=tf.keras.models.load_model(\"models/my_model.h5\")\n",
    "model=tf.keras.models.load_model(\"models/my_model\")\n",
    "\n",
    "#вохзможно в Windows работает только .h5 (по крайней мере у меня)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Редактирование модели: выделение и встраивание слоев, фиксация весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 3)                 9         \n",
      "=================================================================\n",
      "Total params: 19\n",
      "Trainable params: 0\n",
      "Non-trainable params: 19\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "#Выделение слоев\n",
    "\n",
    "#выделение первых 2-х слоев в новую модель\n",
    "model_2 = Model(inputs=model.input, outputs=model.layers[1].output, name=\"MLP_2\")\n",
    "\n",
    "#фиксирование весов (non-trainable)\n",
    "for layer in model_p1.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "layer3_new (Dense)           (None, 24)                96        \n",
      "_________________________________________________________________\n",
      "layer4_new (Dense)           (None, 8)                 200       \n",
      "_________________________________________________________________\n",
      "layer5_new (Dense)           (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 305\n",
      "Non-trainable params: 19\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Добавление новых слоев\n",
    "p2=layers.Dense(24, activation=\"sigmoid\", name=\"layer3_new\")(model_2.output)\n",
    "p2=layers.Dense(8, activation=\"sigmoid\", name=\"layer4_new\")(p2)\n",
    "p2=layers.Dense(1, name=\"layer5_new\")(p2)\n",
    "\n",
    "#пересобираем модель с новым слоем\n",
    "model_3=Model(inputs=[model_2.input], outputs=[p2], name=\"MLP_3\")\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение и обучение пройденных моделей:\n",
    "\n",
    "### 1. Многослойный перцептрон\n",
    "\n",
    "источник данных: www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.029125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch      Fare\n",
       "0              1         0     0.3    1  0.22    0.1    0.0  0.007250\n",
       "1              2         1     0.1    0  0.38    0.1    0.0  0.071283\n",
       "2              3         1     0.3    0  0.26    0.0    0.0  0.007925\n",
       "3              4         1     0.1    0  0.35    0.1    0.0  0.053100\n",
       "4              5         0     0.3    1  0.35    0.0    0.0  0.008050\n",
       "..           ...       ...     ...  ...   ...    ...    ...       ...\n",
       "709          886         0     0.3    0  0.39    0.0    0.5  0.029125\n",
       "710          887         0     0.2    1  0.27    0.0    0.0  0.013000\n",
       "711          888         1     0.1    0  0.19    0.0    0.0  0.030000\n",
       "712          890         1     0.1    1  0.26    0.0    0.0  0.030000\n",
       "713          891         0     0.3    1  0.32    0.0    0.0  0.007750\n",
       "\n",
       "[714 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('titanic_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.3      , 1.       , 0.22     , 0.1      , 0.       , 0.00725  ],\n",
       "        [0.1      , 0.       , 0.38     , 0.1      , 0.       , 0.0712833],\n",
       "        [0.3      , 0.       , 0.26     , 0.       , 0.       , 0.007925 ],\n",
       "        ...,\n",
       "        [0.1      , 0.       , 0.19     , 0.       , 0.       , 0.03     ],\n",
       "        [0.1      , 1.       , 0.26     , 0.       , 0.       , 0.03     ],\n",
       "        [0.3      , 1.       , 0.32     , 0.       , 0.       , 0.00775  ]]),\n",
       " array([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=data[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]].values\n",
    "y_train=data[[\"Survived\"]].values\n",
    "\n",
    "x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((114, 6), (114, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test=x_train[600:714]\n",
    "y_test=y_train[600:714]\n",
    "x_train=x_train[0:600]\n",
    "y_train=y_train[0:600]\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_titanic\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 5)                 35        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 50\n",
      "Trainable params: 50\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# создем модель\n",
    "from keras import layers\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(6,)),\n",
    "        layers.Dense(5, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(2, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\", name=\"layer3\"),\n",
    "    ],\n",
    "    name=\"MLP_titanic\"\n",
    ")\n",
    "\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "#оптимизатор (SGD - стохастический градиентный спуск)\n",
    "opt = keras.optimizers.SGD(learning_rate=0.3)\n",
    "# learning_rate - скорость обучения\n",
    "\n",
    "#функция потерь\n",
    "f_loss = losses.BinaryCrossentropy()\n",
    "\n",
    "#НОВОЕ: метрика - гиперпараметр валидации (accuracy - достигнутая точность)\n",
    "        #под валидацией понимается тестирование в процессе обучения\n",
    "met = ['accuracy']\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,  \n",
    "    loss=f_loss,  \n",
    "    metrics=met, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.5798 - val_loss: 0.6694 - val_accuracy: 0.5965\n",
      "Epoch 2/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.5938 - val_loss: 0.6647 - val_accuracy: 0.5965\n",
      "Epoch 3/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6609 - accuracy: 0.6022 - val_loss: 0.6519 - val_accuracy: 0.5965\n",
      "Epoch 4/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6022 - val_loss: 0.6332 - val_accuracy: 0.5965\n",
      "Epoch 5/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6280 - accuracy: 0.6359 - val_loss: 0.6034 - val_accuracy: 0.7281\n",
      "Epoch 6/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.7493 - val_loss: 0.5654 - val_accuracy: 0.7982\n",
      "Epoch 7/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.7773 - val_loss: 0.5368 - val_accuracy: 0.7982\n",
      "Epoch 8/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.7801 - val_loss: 0.5153 - val_accuracy: 0.7982\n",
      "Epoch 9/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5350 - accuracy: 0.7801 - val_loss: 0.5073 - val_accuracy: 0.7982\n",
      "Epoch 10/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7801 - val_loss: 0.5074 - val_accuracy: 0.7982\n",
      "Epoch 11/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5302 - accuracy: 0.7801 - val_loss: 0.5034 - val_accuracy: 0.7982\n",
      "Epoch 12/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5262 - accuracy: 0.7801 - val_loss: 0.5078 - val_accuracy: 0.7982\n",
      "Epoch 13/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.7801 - val_loss: 0.4983 - val_accuracy: 0.7982\n",
      "Epoch 14/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.7801 - val_loss: 0.4967 - val_accuracy: 0.7982\n",
      "Epoch 15/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7801 - val_loss: 0.4979 - val_accuracy: 0.7982\n",
      "Epoch 16/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.7801 - val_loss: 0.4971 - val_accuracy: 0.7982\n",
      "Epoch 17/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7801 - val_loss: 0.4963 - val_accuracy: 0.7982\n",
      "Epoch 18/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7801 - val_loss: 0.4918 - val_accuracy: 0.7982\n",
      "Epoch 19/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7801 - val_loss: 0.4880 - val_accuracy: 0.7982\n",
      "Epoch 20/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7801 - val_loss: 0.4867 - val_accuracy: 0.7982\n",
      "Epoch 21/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7801 - val_loss: 0.4849 - val_accuracy: 0.7982\n",
      "Epoch 22/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7829 - val_loss: 0.4846 - val_accuracy: 0.8070\n",
      "Epoch 23/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7815 - val_loss: 0.4817 - val_accuracy: 0.7982\n",
      "Epoch 24/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7815 - val_loss: 0.4797 - val_accuracy: 0.7982\n",
      "Epoch 25/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7815 - val_loss: 0.4799 - val_accuracy: 0.8158\n",
      "Epoch 26/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7815 - val_loss: 0.4920 - val_accuracy: 0.8246\n",
      "Epoch 27/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7843 - val_loss: 0.4747 - val_accuracy: 0.8158\n",
      "Epoch 28/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7829 - val_loss: 0.4708 - val_accuracy: 0.8070\n",
      "Epoch 29/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7899 - val_loss: 0.4682 - val_accuracy: 0.8070\n",
      "Epoch 30/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7941 - val_loss: 0.4688 - val_accuracy: 0.8158\n",
      "Epoch 31/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7913 - val_loss: 0.4721 - val_accuracy: 0.7982\n",
      "Epoch 32/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.7857 - val_loss: 0.4636 - val_accuracy: 0.8158\n",
      "Epoch 33/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7857 - val_loss: 0.4617 - val_accuracy: 0.8158\n",
      "Epoch 34/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7899 - val_loss: 0.4601 - val_accuracy: 0.8158\n",
      "Epoch 35/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7913 - val_loss: 0.4876 - val_accuracy: 0.7982\n",
      "Epoch 36/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7941 - val_loss: 0.4610 - val_accuracy: 0.8070\n",
      "Epoch 37/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7899 - val_loss: 0.4549 - val_accuracy: 0.8070\n",
      "Epoch 38/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7899 - val_loss: 0.4584 - val_accuracy: 0.8246\n",
      "Epoch 39/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8039 - val_loss: 0.4501 - val_accuracy: 0.8158\n",
      "Epoch 40/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7899 - val_loss: 0.4535 - val_accuracy: 0.8246\n",
      "Epoch 41/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7941 - val_loss: 0.4642 - val_accuracy: 0.7982\n",
      "Epoch 42/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7941 - val_loss: 0.4466 - val_accuracy: 0.8246\n",
      "Epoch 43/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.8011 - val_loss: 0.4924 - val_accuracy: 0.7719\n",
      "Epoch 44/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.8025 - val_loss: 0.4647 - val_accuracy: 0.7982\n",
      "Epoch 45/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7913 - val_loss: 0.4405 - val_accuracy: 0.8158\n",
      "Epoch 46/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7927 - val_loss: 0.4312 - val_accuracy: 0.8158\n",
      "Epoch 47/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8011 - val_loss: 0.4542 - val_accuracy: 0.7807\n",
      "Epoch 48/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7927 - val_loss: 0.4423 - val_accuracy: 0.8158\n",
      "Epoch 49/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.8025 - val_loss: 0.4421 - val_accuracy: 0.7895\n",
      "Epoch 50/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.8011 - val_loss: 0.4208 - val_accuracy: 0.8158\n",
      "Epoch 51/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7927 - val_loss: 0.4428 - val_accuracy: 0.8070\n",
      "Epoch 52/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.8053 - val_loss: 0.4449 - val_accuracy: 0.7807\n",
      "Epoch 53/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7969 - val_loss: 0.4176 - val_accuracy: 0.8246\n",
      "Epoch 54/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.8011 - val_loss: 0.4252 - val_accuracy: 0.8070\n",
      "Epoch 55/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.8095 - val_loss: 0.4373 - val_accuracy: 0.7982\n",
      "Epoch 56/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7955 - val_loss: 0.4159 - val_accuracy: 0.8158\n",
      "Epoch 57/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.8095 - val_loss: 0.4346 - val_accuracy: 0.7982\n",
      "Epoch 58/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7997 - val_loss: 0.4199 - val_accuracy: 0.7982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.8067 - val_loss: 0.4876 - val_accuracy: 0.7719\n",
      "Epoch 60/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8067 - val_loss: 0.4106 - val_accuracy: 0.7982\n",
      "Epoch 61/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.8095 - val_loss: 0.4233 - val_accuracy: 0.7982\n",
      "Epoch 62/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.8067 - val_loss: 0.4090 - val_accuracy: 0.8333\n",
      "Epoch 63/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8025 - val_loss: 0.4112 - val_accuracy: 0.8246\n",
      "Epoch 64/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.8081 - val_loss: 0.4237 - val_accuracy: 0.7982\n",
      "Epoch 65/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.8053 - val_loss: 0.4518 - val_accuracy: 0.7895\n",
      "Epoch 66/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7955 - val_loss: 0.4061 - val_accuracy: 0.8246\n",
      "Epoch 67/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7969 - val_loss: 0.4008 - val_accuracy: 0.7982\n",
      "Epoch 68/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.8039 - val_loss: 0.4185 - val_accuracy: 0.8158\n",
      "Epoch 69/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7913 - val_loss: 0.3947 - val_accuracy: 0.8158\n",
      "Epoch 70/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7955 - val_loss: 0.4059 - val_accuracy: 0.8158\n",
      "Epoch 71/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8011 - val_loss: 0.4135 - val_accuracy: 0.8246\n",
      "Epoch 72/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7997 - val_loss: 0.4111 - val_accuracy: 0.8070\n",
      "Epoch 73/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.8053 - val_loss: 0.4288 - val_accuracy: 0.7895\n",
      "Epoch 74/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7969 - val_loss: 0.4193 - val_accuracy: 0.7982\n",
      "Epoch 75/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7941 - val_loss: 0.3911 - val_accuracy: 0.8333\n",
      "Epoch 76/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8137 - val_loss: 0.3962 - val_accuracy: 0.8421\n",
      "Epoch 77/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.8053 - val_loss: 0.3934 - val_accuracy: 0.8333\n",
      "Epoch 78/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.8053 - val_loss: 0.3977 - val_accuracy: 0.8158\n",
      "Epoch 79/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.8053 - val_loss: 0.4127 - val_accuracy: 0.8158\n",
      "Epoch 80/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.8053 - val_loss: 0.3975 - val_accuracy: 0.8246\n",
      "Epoch 81/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.8109 - val_loss: 0.3902 - val_accuracy: 0.8421\n",
      "Epoch 82/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.8109 - val_loss: 0.4501 - val_accuracy: 0.7719\n",
      "Epoch 83/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8109 - val_loss: 0.4574 - val_accuracy: 0.7632\n",
      "Epoch 84/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.8039 - val_loss: 0.3889 - val_accuracy: 0.8333\n",
      "Epoch 85/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7955 - val_loss: 0.4002 - val_accuracy: 0.8333\n",
      "Epoch 86/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.8053 - val_loss: 0.4043 - val_accuracy: 0.8333\n",
      "Epoch 87/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.8123 - val_loss: 0.3974 - val_accuracy: 0.8158\n",
      "Epoch 88/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.8109 - val_loss: 0.3863 - val_accuracy: 0.8509\n",
      "Epoch 89/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8109 - val_loss: 0.3846 - val_accuracy: 0.8246\n",
      "Epoch 90/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7969 - val_loss: 0.3840 - val_accuracy: 0.8421\n",
      "Epoch 91/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.8123 - val_loss: 0.3841 - val_accuracy: 0.8333\n",
      "Epoch 92/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.8067 - val_loss: 0.3859 - val_accuracy: 0.8333\n",
      "Epoch 93/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8137 - val_loss: 0.3901 - val_accuracy: 0.8421\n",
      "Epoch 94/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.8165 - val_loss: 0.3845 - val_accuracy: 0.8596\n",
      "Epoch 95/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8053 - val_loss: 0.4370 - val_accuracy: 0.7807\n",
      "Epoch 96/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.8067 - val_loss: 0.3915 - val_accuracy: 0.8509\n",
      "Epoch 97/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.8095 - val_loss: 0.5048 - val_accuracy: 0.7544\n",
      "Epoch 98/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.8011 - val_loss: 0.3847 - val_accuracy: 0.8333\n",
      "Epoch 99/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8039 - val_loss: 0.3794 - val_accuracy: 0.8421\n",
      "Epoch 100/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.8039 - val_loss: 0.3797 - val_accuracy: 0.8509\n",
      "Epoch 101/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.8109 - val_loss: 0.4014 - val_accuracy: 0.8246\n",
      "Epoch 102/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.8053 - val_loss: 0.4182 - val_accuracy: 0.7895\n",
      "Epoch 103/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.8053 - val_loss: 0.3920 - val_accuracy: 0.8158\n",
      "Epoch 104/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.8193 - val_loss: 0.3809 - val_accuracy: 0.8158\n",
      "Epoch 105/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.8109 - val_loss: 0.4004 - val_accuracy: 0.7982\n",
      "Epoch 106/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8123 - val_loss: 0.4108 - val_accuracy: 0.8070\n",
      "Epoch 107/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.8053 - val_loss: 0.4173 - val_accuracy: 0.7895\n",
      "Epoch 108/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8207 - val_loss: 0.3900 - val_accuracy: 0.8421\n",
      "Epoch 109/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.8123 - val_loss: 0.3854 - val_accuracy: 0.8421\n",
      "Epoch 110/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.8179 - val_loss: 0.3990 - val_accuracy: 0.8158\n",
      "Epoch 111/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8165 - val_loss: 0.3920 - val_accuracy: 0.8158\n",
      "Epoch 112/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8081 - val_loss: 0.3943 - val_accuracy: 0.8421\n",
      "Epoch 113/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.8123 - val_loss: 0.3811 - val_accuracy: 0.8333\n",
      "Epoch 114/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.8095 - val_loss: 0.3750 - val_accuracy: 0.8596\n",
      "Epoch 115/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.8067 - val_loss: 0.4222 - val_accuracy: 0.7895\n",
      "Epoch 116/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.8235 - val_loss: 0.3747 - val_accuracy: 0.8596\n",
      "Epoch 117/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.8081 - val_loss: 0.3950 - val_accuracy: 0.8158\n",
      "Epoch 118/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.8151 - val_loss: 0.3738 - val_accuracy: 0.8421\n",
      "Epoch 119/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.8207 - val_loss: 0.4006 - val_accuracy: 0.8158\n",
      "Epoch 120/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8109 - val_loss: 0.3936 - val_accuracy: 0.8070\n",
      "Epoch 121/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.8179 - val_loss: 0.3848 - val_accuracy: 0.8421\n",
      "Epoch 122/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.8179 - val_loss: 0.4404 - val_accuracy: 0.7982\n",
      "Epoch 123/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8053 - val_loss: 0.3783 - val_accuracy: 0.8596\n",
      "Epoch 124/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.8179 - val_loss: 0.3845 - val_accuracy: 0.8509\n",
      "Epoch 125/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.8095 - val_loss: 0.4263 - val_accuracy: 0.7895\n",
      "Epoch 126/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.8235 - val_loss: 0.3727 - val_accuracy: 0.8684\n",
      "Epoch 127/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.8165 - val_loss: 0.3749 - val_accuracy: 0.8333\n",
      "Epoch 128/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8053 - val_loss: 0.4183 - val_accuracy: 0.7982\n",
      "Epoch 129/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.8165 - val_loss: 0.3993 - val_accuracy: 0.8070\n",
      "Epoch 130/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.8137 - val_loss: 0.3955 - val_accuracy: 0.8246\n",
      "Epoch 131/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8095 - val_loss: 0.3702 - val_accuracy: 0.8509\n",
      "Epoch 132/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.8263 - val_loss: 0.4113 - val_accuracy: 0.7982\n",
      "Epoch 133/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.8137 - val_loss: 0.3755 - val_accuracy: 0.8684\n",
      "Epoch 134/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.8123 - val_loss: 0.3919 - val_accuracy: 0.8333\n",
      "Epoch 135/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.8249 - val_loss: 0.4121 - val_accuracy: 0.8070\n",
      "Epoch 136/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.8179 - val_loss: 0.3881 - val_accuracy: 0.8070\n",
      "Epoch 137/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.8151 - val_loss: 0.4244 - val_accuracy: 0.7982\n",
      "Epoch 138/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.8193 - val_loss: 0.3744 - val_accuracy: 0.8509\n",
      "Epoch 139/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8095 - val_loss: 0.3705 - val_accuracy: 0.8509\n",
      "Epoch 140/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.8067 - val_loss: 0.3699 - val_accuracy: 0.8421\n",
      "Epoch 141/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.8165 - val_loss: 0.3701 - val_accuracy: 0.8421\n",
      "Epoch 142/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.8109 - val_loss: 0.3871 - val_accuracy: 0.8246\n",
      "Epoch 143/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.8053 - val_loss: 0.3713 - val_accuracy: 0.8684\n",
      "Epoch 144/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.8179 - val_loss: 0.3681 - val_accuracy: 0.8421\n",
      "Epoch 145/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.8137 - val_loss: 0.3898 - val_accuracy: 0.8158\n",
      "Epoch 146/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8235 - val_loss: 0.3729 - val_accuracy: 0.8509\n",
      "Epoch 147/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8109 - val_loss: 0.3744 - val_accuracy: 0.8509\n",
      "Epoch 148/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.8123 - val_loss: 0.3832 - val_accuracy: 0.8421\n",
      "Epoch 149/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.8207 - val_loss: 0.3729 - val_accuracy: 0.8596\n",
      "Epoch 150/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8165 - val_loss: 0.3796 - val_accuracy: 0.8421\n",
      "Epoch 151/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.8151 - val_loss: 0.3938 - val_accuracy: 0.8158\n",
      "Epoch 152/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8193 - val_loss: 0.3867 - val_accuracy: 0.8333\n",
      "Epoch 153/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8067 - val_loss: 0.3743 - val_accuracy: 0.8421\n",
      "Epoch 154/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.8221 - val_loss: 0.3672 - val_accuracy: 0.8421\n",
      "Epoch 155/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.8263 - val_loss: 0.3702 - val_accuracy: 0.8596\n",
      "Epoch 156/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8193 - val_loss: 0.3663 - val_accuracy: 0.8421\n",
      "Epoch 157/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.8137 - val_loss: 0.3683 - val_accuracy: 0.8596\n",
      "Epoch 158/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.8137 - val_loss: 0.3664 - val_accuracy: 0.8509\n",
      "Epoch 159/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8123 - val_loss: 0.3805 - val_accuracy: 0.8333\n",
      "Epoch 160/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8249 - val_loss: 0.4236 - val_accuracy: 0.7895\n",
      "Epoch 161/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.8151 - val_loss: 0.4333 - val_accuracy: 0.7895\n",
      "Epoch 162/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.8193 - val_loss: 0.3752 - val_accuracy: 0.8421\n",
      "Epoch 163/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.8081 - val_loss: 0.3846 - val_accuracy: 0.8333\n",
      "Epoch 164/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.8207 - val_loss: 0.3804 - val_accuracy: 0.8509\n",
      "Epoch 165/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.8067 - val_loss: 0.3838 - val_accuracy: 0.8246\n",
      "Epoch 166/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.8179 - val_loss: 0.3834 - val_accuracy: 0.8596\n",
      "Epoch 167/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.8221 - val_loss: 0.4019 - val_accuracy: 0.8246\n",
      "Epoch 168/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.8151 - val_loss: 0.3662 - val_accuracy: 0.8509\n",
      "Epoch 169/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.8179 - val_loss: 0.3649 - val_accuracy: 0.8421\n",
      "Epoch 170/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8095 - val_loss: 0.3671 - val_accuracy: 0.8509\n",
      "Epoch 171/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.8193 - val_loss: 0.3770 - val_accuracy: 0.8421\n",
      "Epoch 172/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8151 - val_loss: 0.4052 - val_accuracy: 0.8158\n",
      "Epoch 173/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8109 - val_loss: 0.3747 - val_accuracy: 0.8421\n",
      "Epoch 174/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8165 - val_loss: 0.3886 - val_accuracy: 0.8333\n",
      "Epoch 175/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8193 - val_loss: 0.4073 - val_accuracy: 0.8070\n",
      "Epoch 176/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8193 - val_loss: 0.3748 - val_accuracy: 0.8509\n",
      "Epoch 177/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.8193 - val_loss: 0.3934 - val_accuracy: 0.8333\n",
      "Epoch 178/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8165 - val_loss: 0.5191 - val_accuracy: 0.7719\n",
      "Epoch 179/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.8151 - val_loss: 0.3638 - val_accuracy: 0.8421\n",
      "Epoch 180/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.8207 - val_loss: 0.4405 - val_accuracy: 0.7982\n",
      "Epoch 181/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4227 - accuracy: 0.8207 - val_loss: 0.3712 - val_accuracy: 0.8509\n",
      "Epoch 182/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.8221 - val_loss: 0.3834 - val_accuracy: 0.8333\n",
      "Epoch 183/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8193 - val_loss: 0.4191 - val_accuracy: 0.7982\n",
      "Epoch 184/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8207 - val_loss: 0.3613 - val_accuracy: 0.8421\n",
      "Epoch 185/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8151 - val_loss: 0.4191 - val_accuracy: 0.7895\n",
      "Epoch 186/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.8109 - val_loss: 0.3614 - val_accuracy: 0.8596\n",
      "Epoch 187/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.8151 - val_loss: 0.3634 - val_accuracy: 0.8596\n",
      "Epoch 188/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.8193 - val_loss: 0.3673 - val_accuracy: 0.8509\n",
      "Epoch 189/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.8249 - val_loss: 0.3602 - val_accuracy: 0.8684\n",
      "Epoch 190/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.8137 - val_loss: 0.3598 - val_accuracy: 0.8596\n",
      "Epoch 191/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8137 - val_loss: 0.3620 - val_accuracy: 0.8509\n",
      "Epoch 192/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.8207 - val_loss: 0.3632 - val_accuracy: 0.8596\n",
      "Epoch 193/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.8235 - val_loss: 0.3627 - val_accuracy: 0.8421\n",
      "Epoch 194/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.8207 - val_loss: 0.3612 - val_accuracy: 0.8684\n",
      "Epoch 195/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8193 - val_loss: 0.3616 - val_accuracy: 0.8509\n",
      "Epoch 196/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8277 - val_loss: 0.3747 - val_accuracy: 0.8596\n",
      "Epoch 197/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.8053 - val_loss: 0.3611 - val_accuracy: 0.8509\n",
      "Epoch 198/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4332 - accuracy: 0.8193 - val_loss: 0.3599 - val_accuracy: 0.8509\n",
      "Epoch 199/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8179 - val_loss: 0.3694 - val_accuracy: 0.8684\n",
      "Epoch 200/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.8123 - val_loss: 0.3731 - val_accuracy: 0.8509\n",
      "Epoch 201/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.8207 - val_loss: 0.3678 - val_accuracy: 0.8421\n",
      "Epoch 202/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8207 - val_loss: 0.3668 - val_accuracy: 0.8509\n",
      "Epoch 203/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.8151 - val_loss: 0.3774 - val_accuracy: 0.8596\n",
      "Epoch 204/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.8137 - val_loss: 0.3641 - val_accuracy: 0.8684\n",
      "Epoch 205/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.8179 - val_loss: 0.3593 - val_accuracy: 0.8772\n",
      "Epoch 206/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.8151 - val_loss: 0.3746 - val_accuracy: 0.8333\n",
      "Epoch 207/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.8123 - val_loss: 0.3546 - val_accuracy: 0.8509\n",
      "Epoch 208/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.8179 - val_loss: 0.3609 - val_accuracy: 0.8509\n",
      "Epoch 209/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.8249 - val_loss: 0.3577 - val_accuracy: 0.8509\n",
      "Epoch 210/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8319 - val_loss: 0.3763 - val_accuracy: 0.8333\n",
      "Epoch 211/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.8137 - val_loss: 0.4103 - val_accuracy: 0.8070\n",
      "Epoch 212/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.8095 - val_loss: 0.3668 - val_accuracy: 0.8509\n",
      "Epoch 213/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.8221 - val_loss: 0.3597 - val_accuracy: 0.8421\n",
      "Epoch 214/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.8151 - val_loss: 0.3704 - val_accuracy: 0.8421\n",
      "Epoch 215/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4232 - accuracy: 0.8207 - val_loss: 0.4575 - val_accuracy: 0.7895\n",
      "Epoch 216/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8193 - val_loss: 0.3584 - val_accuracy: 0.8509\n",
      "Epoch 217/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4249 - accuracy: 0.8193 - val_loss: 0.3647 - val_accuracy: 0.8684\n",
      "Epoch 218/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4226 - accuracy: 0.8109 - val_loss: 0.3553 - val_accuracy: 0.8421\n",
      "Epoch 219/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.8179 - val_loss: 0.3747 - val_accuracy: 0.8596\n",
      "Epoch 220/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.8151 - val_loss: 0.3569 - val_accuracy: 0.8596\n",
      "Epoch 221/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.8235 - val_loss: 0.3787 - val_accuracy: 0.8421\n",
      "Epoch 222/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8193 - val_loss: 0.3572 - val_accuracy: 0.8421\n",
      "Epoch 223/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8151 - val_loss: 0.4503 - val_accuracy: 0.7895\n",
      "Epoch 224/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4236 - accuracy: 0.8207 - val_loss: 0.3662 - val_accuracy: 0.8684\n",
      "Epoch 225/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4241 - accuracy: 0.8235 - val_loss: 0.3516 - val_accuracy: 0.8684\n",
      "Epoch 226/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.8165 - val_loss: 0.3634 - val_accuracy: 0.8421\n",
      "Epoch 227/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.8137 - val_loss: 0.3532 - val_accuracy: 0.8509\n",
      "Epoch 228/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8179 - val_loss: 0.3568 - val_accuracy: 0.8772\n",
      "Epoch 229/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8263 - val_loss: 0.3869 - val_accuracy: 0.8246\n",
      "Epoch 230/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8221 - val_loss: 0.3545 - val_accuracy: 0.8684\n",
      "Epoch 231/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8221 - val_loss: 0.3563 - val_accuracy: 0.8596\n",
      "Epoch 232/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.8207 - val_loss: 0.3539 - val_accuracy: 0.8772\n",
      "Epoch 233/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.8179 - val_loss: 0.3663 - val_accuracy: 0.8684\n",
      "Epoch 234/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.8193 - val_loss: 0.3978 - val_accuracy: 0.8246\n",
      "Epoch 235/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.8137 - val_loss: 0.3612 - val_accuracy: 0.8421\n",
      "Epoch 236/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8179 - val_loss: 0.3675 - val_accuracy: 0.8421\n",
      "Epoch 237/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.8221 - val_loss: 0.3485 - val_accuracy: 0.8509\n",
      "Epoch 238/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.8193 - val_loss: 0.3733 - val_accuracy: 0.8421\n",
      "Epoch 239/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.8165 - val_loss: 0.3694 - val_accuracy: 0.8684\n",
      "Epoch 240/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8123 - val_loss: 0.3740 - val_accuracy: 0.8333\n",
      "Epoch 241/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.8179 - val_loss: 0.3799 - val_accuracy: 0.8333\n",
      "Epoch 242/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8249 - val_loss: 0.3564 - val_accuracy: 0.8421\n",
      "Epoch 243/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8193 - val_loss: 0.3673 - val_accuracy: 0.8333\n",
      "Epoch 244/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.8109 - val_loss: 0.3533 - val_accuracy: 0.8596\n",
      "Epoch 245/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8207 - val_loss: 0.4151 - val_accuracy: 0.7982\n",
      "Epoch 246/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8361 - val_loss: 0.3482 - val_accuracy: 0.8596\n",
      "Epoch 247/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.8165 - val_loss: 0.3508 - val_accuracy: 0.8509\n",
      "Epoch 248/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8235 - val_loss: 0.3542 - val_accuracy: 0.8860\n",
      "Epoch 249/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8151 - val_loss: 0.3525 - val_accuracy: 0.8772\n",
      "Epoch 250/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4207 - accuracy: 0.8263 - val_loss: 0.3508 - val_accuracy: 0.8684\n",
      "Epoch 251/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.8151 - val_loss: 0.3744 - val_accuracy: 0.8421\n",
      "Epoch 252/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8235 - val_loss: 0.3670 - val_accuracy: 0.8684\n",
      "Epoch 253/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8137 - val_loss: 0.3528 - val_accuracy: 0.8596\n",
      "Epoch 254/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8095 - val_loss: 0.4424 - val_accuracy: 0.8158\n",
      "Epoch 255/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.8249 - val_loss: 0.3571 - val_accuracy: 0.8509\n",
      "Epoch 256/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8235 - val_loss: 0.3621 - val_accuracy: 0.8684\n",
      "Epoch 257/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8277 - val_loss: 0.3720 - val_accuracy: 0.8509\n",
      "Epoch 258/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8235 - val_loss: 0.3843 - val_accuracy: 0.8246\n",
      "Epoch 259/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8263 - val_loss: 0.3546 - val_accuracy: 0.8772\n",
      "Epoch 260/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.8207 - val_loss: 0.3523 - val_accuracy: 0.8509\n",
      "Epoch 261/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.8193 - val_loss: 0.3499 - val_accuracy: 0.8772\n",
      "Epoch 262/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8263 - val_loss: 0.3459 - val_accuracy: 0.8684\n",
      "Epoch 263/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4195 - accuracy: 0.8221 - val_loss: 0.3502 - val_accuracy: 0.8684\n",
      "Epoch 264/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8221 - val_loss: 0.3626 - val_accuracy: 0.8509\n",
      "Epoch 265/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.8249 - val_loss: 0.3513 - val_accuracy: 0.8509\n",
      "Epoch 266/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8249 - val_loss: 0.3723 - val_accuracy: 0.8333\n",
      "Epoch 267/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8207 - val_loss: 0.3609 - val_accuracy: 0.8421\n",
      "Epoch 268/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8137 - val_loss: 0.3566 - val_accuracy: 0.8509\n",
      "Epoch 269/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8207 - val_loss: 0.3520 - val_accuracy: 0.8509\n",
      "Epoch 270/400\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8165 - val_loss: 0.3525 - val_accuracy: 0.8860\n",
      "Epoch 271/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8109 - val_loss: 0.3463 - val_accuracy: 0.8684\n",
      "Epoch 272/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8221 - val_loss: 0.3542 - val_accuracy: 0.8596\n",
      "Epoch 273/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8249 - val_loss: 0.3512 - val_accuracy: 0.8509\n",
      "Epoch 274/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8221 - val_loss: 0.3542 - val_accuracy: 0.8772\n",
      "Epoch 275/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8151 - val_loss: 0.3573 - val_accuracy: 0.8421\n",
      "Epoch 276/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8333 - val_loss: 0.3742 - val_accuracy: 0.8509\n",
      "Epoch 277/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4101 - accuracy: 0.8333 - val_loss: 0.3496 - val_accuracy: 0.8684\n",
      "Epoch 278/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4217 - accuracy: 0.8193 - val_loss: 0.3495 - val_accuracy: 0.8772\n",
      "Epoch 279/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8151 - val_loss: 0.3821 - val_accuracy: 0.8421\n",
      "Epoch 280/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8207 - val_loss: 0.3479 - val_accuracy: 0.8684\n",
      "Epoch 281/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.8249 - val_loss: 0.3636 - val_accuracy: 0.8333\n",
      "Epoch 282/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.8235 - val_loss: 0.3457 - val_accuracy: 0.8684\n",
      "Epoch 283/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8333 - val_loss: 0.3495 - val_accuracy: 0.8684\n",
      "Epoch 284/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8179 - val_loss: 0.4684 - val_accuracy: 0.7982\n",
      "Epoch 285/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4219 - accuracy: 0.8235 - val_loss: 0.3624 - val_accuracy: 0.8421\n",
      "Epoch 286/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8137 - val_loss: 0.3485 - val_accuracy: 0.8509\n",
      "Epoch 287/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8249 - val_loss: 0.3613 - val_accuracy: 0.8684\n",
      "Epoch 288/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8221 - val_loss: 0.4063 - val_accuracy: 0.8246\n",
      "Epoch 289/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.8179 - val_loss: 0.3501 - val_accuracy: 0.8684\n",
      "Epoch 290/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4200 - accuracy: 0.8137 - val_loss: 0.3560 - val_accuracy: 0.8509\n",
      "Epoch 291/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.8151 - val_loss: 0.3727 - val_accuracy: 0.8333\n",
      "Epoch 292/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8291 - val_loss: 0.3713 - val_accuracy: 0.8509\n",
      "Epoch 293/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.8249 - val_loss: 0.3506 - val_accuracy: 0.8596\n",
      "Epoch 294/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8207 - val_loss: 0.3463 - val_accuracy: 0.8596\n",
      "Epoch 295/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8193 - val_loss: 0.3857 - val_accuracy: 0.8333\n",
      "Epoch 296/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8221 - val_loss: 0.3445 - val_accuracy: 0.8772\n",
      "Epoch 297/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8263 - val_loss: 0.3470 - val_accuracy: 0.8596\n",
      "Epoch 298/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.8207 - val_loss: 0.3524 - val_accuracy: 0.8684\n",
      "Epoch 299/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4184 - accuracy: 0.8207 - val_loss: 0.3445 - val_accuracy: 0.8684\n",
      "Epoch 300/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8305 - val_loss: 0.3515 - val_accuracy: 0.8684\n",
      "Epoch 301/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8123 - val_loss: 0.3533 - val_accuracy: 0.8596\n",
      "Epoch 302/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8291 - val_loss: 0.3527 - val_accuracy: 0.8772\n",
      "Epoch 303/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8235 - val_loss: 0.3577 - val_accuracy: 0.8509\n",
      "Epoch 304/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8221 - val_loss: 0.3465 - val_accuracy: 0.8596\n",
      "Epoch 305/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4199 - accuracy: 0.8193 - val_loss: 0.3700 - val_accuracy: 0.8421\n",
      "Epoch 306/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.8221 - val_loss: 0.3475 - val_accuracy: 0.8596\n",
      "Epoch 307/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8221 - val_loss: 0.3448 - val_accuracy: 0.8596\n",
      "Epoch 308/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8319 - val_loss: 0.3438 - val_accuracy: 0.8596\n",
      "Epoch 309/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4189 - accuracy: 0.8235 - val_loss: 0.3438 - val_accuracy: 0.8684\n",
      "Epoch 310/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8179 - val_loss: 0.3546 - val_accuracy: 0.8509\n",
      "Epoch 311/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.8207 - val_loss: 0.3437 - val_accuracy: 0.8596\n",
      "Epoch 312/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8235 - val_loss: 0.3411 - val_accuracy: 0.8684\n",
      "Epoch 313/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8305 - val_loss: 0.3554 - val_accuracy: 0.8509\n",
      "Epoch 314/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8291 - val_loss: 0.3519 - val_accuracy: 0.8684\n",
      "Epoch 315/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8235 - val_loss: 0.3611 - val_accuracy: 0.8421\n",
      "Epoch 316/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4195 - accuracy: 0.8151 - val_loss: 0.3492 - val_accuracy: 0.8596\n",
      "Epoch 317/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8165 - val_loss: 0.3537 - val_accuracy: 0.8772\n",
      "Epoch 318/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8305 - val_loss: 0.3442 - val_accuracy: 0.8596\n",
      "Epoch 319/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8207 - val_loss: 0.3482 - val_accuracy: 0.8596\n",
      "Epoch 320/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8193 - val_loss: 0.3431 - val_accuracy: 0.8596\n",
      "Epoch 321/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8207 - val_loss: 0.3440 - val_accuracy: 0.8596\n",
      "Epoch 322/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8221 - val_loss: 0.3452 - val_accuracy: 0.8596\n",
      "Epoch 323/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8179 - val_loss: 0.3487 - val_accuracy: 0.8772\n",
      "Epoch 324/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8249 - val_loss: 0.4153 - val_accuracy: 0.8158\n",
      "Epoch 325/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.8249 - val_loss: 0.3407 - val_accuracy: 0.8596\n",
      "Epoch 326/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.8193 - val_loss: 0.3617 - val_accuracy: 0.8596\n",
      "Epoch 327/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.8249 - val_loss: 0.3448 - val_accuracy: 0.8684\n",
      "Epoch 328/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8277 - val_loss: 0.3434 - val_accuracy: 0.8684\n",
      "Epoch 329/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4184 - accuracy: 0.8193 - val_loss: 0.3442 - val_accuracy: 0.8596\n",
      "Epoch 330/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8235 - val_loss: 0.3978 - val_accuracy: 0.8070\n",
      "Epoch 331/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8151 - val_loss: 0.3493 - val_accuracy: 0.8772\n",
      "Epoch 332/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.8221 - val_loss: 0.3530 - val_accuracy: 0.8596\n",
      "Epoch 333/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8291 - val_loss: 0.3429 - val_accuracy: 0.8772\n",
      "Epoch 334/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.8277 - val_loss: 0.3423 - val_accuracy: 0.8772\n",
      "Epoch 335/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8207 - val_loss: 0.3399 - val_accuracy: 0.8509\n",
      "Epoch 336/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.8389 - val_loss: 0.3509 - val_accuracy: 0.8596\n",
      "Epoch 337/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.8263 - val_loss: 0.3453 - val_accuracy: 0.8596\n",
      "Epoch 338/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8235 - val_loss: 0.3431 - val_accuracy: 0.8860\n",
      "Epoch 339/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8375 - val_loss: 0.3675 - val_accuracy: 0.8421\n",
      "Epoch 340/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8179 - val_loss: 0.3501 - val_accuracy: 0.8509\n",
      "Epoch 341/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4120 - accuracy: 0.8319 - val_loss: 0.3708 - val_accuracy: 0.8421\n",
      "Epoch 342/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8235 - val_loss: 0.3458 - val_accuracy: 0.8596\n",
      "Epoch 343/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8277 - val_loss: 0.3510 - val_accuracy: 0.8509\n",
      "Epoch 344/400\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8277 - val_loss: 0.3737 - val_accuracy: 0.8421\n",
      "Epoch 345/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.8137 - val_loss: 0.3457 - val_accuracy: 0.8860\n",
      "Epoch 346/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8221 - val_loss: 0.3420 - val_accuracy: 0.8596\n",
      "Epoch 347/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.8291 - val_loss: 0.3424 - val_accuracy: 0.8596\n",
      "Epoch 348/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4133 - accuracy: 0.8193 - val_loss: 0.3433 - val_accuracy: 0.8596\n",
      "Epoch 349/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.8249 - val_loss: 0.3373 - val_accuracy: 0.8509\n",
      "Epoch 350/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8179 - val_loss: 0.3494 - val_accuracy: 0.8772\n",
      "Epoch 351/400\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.82 - 0s 1ms/step - loss: 0.4151 - accuracy: 0.8235 - val_loss: 0.3464 - val_accuracy: 0.8684\n",
      "Epoch 352/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4127 - accuracy: 0.8305 - val_loss: 0.3418 - val_accuracy: 0.8772\n",
      "Epoch 353/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.8263 - val_loss: 0.3631 - val_accuracy: 0.8596\n",
      "Epoch 354/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8347 - val_loss: 0.3406 - val_accuracy: 0.8772\n",
      "Epoch 355/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8263 - val_loss: 0.3394 - val_accuracy: 0.8684\n",
      "Epoch 356/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8193 - val_loss: 0.3552 - val_accuracy: 0.8509\n",
      "Epoch 357/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8305 - val_loss: 0.3445 - val_accuracy: 0.8596\n",
      "Epoch 358/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8277 - val_loss: 0.3523 - val_accuracy: 0.8684\n",
      "Epoch 359/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8235 - val_loss: 0.3419 - val_accuracy: 0.8772\n",
      "Epoch 360/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.8263 - val_loss: 0.3509 - val_accuracy: 0.8596\n",
      "Epoch 361/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8221 - val_loss: 0.3409 - val_accuracy: 0.8684\n",
      "Epoch 362/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4119 - accuracy: 0.8361 - val_loss: 0.3489 - val_accuracy: 0.8596\n",
      "Epoch 363/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.8263 - val_loss: 0.3407 - val_accuracy: 0.8684\n",
      "Epoch 364/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8193 - val_loss: 0.3458 - val_accuracy: 0.8684\n",
      "Epoch 365/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4137 - accuracy: 0.8207 - val_loss: 0.3392 - val_accuracy: 0.8684\n",
      "Epoch 366/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.8291 - val_loss: 0.3447 - val_accuracy: 0.8596\n",
      "Epoch 367/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8277 - val_loss: 0.3391 - val_accuracy: 0.8509\n",
      "Epoch 368/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.8193 - val_loss: 0.3459 - val_accuracy: 0.8684\n",
      "Epoch 369/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8179 - val_loss: 0.3500 - val_accuracy: 0.8509\n",
      "Epoch 370/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8333 - val_loss: 0.3371 - val_accuracy: 0.8684\n",
      "Epoch 371/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8319 - val_loss: 0.3560 - val_accuracy: 0.8509\n",
      "Epoch 372/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8207 - val_loss: 0.3403 - val_accuracy: 0.8772\n",
      "Epoch 373/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8193 - val_loss: 0.3429 - val_accuracy: 0.8509\n",
      "Epoch 374/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.8249 - val_loss: 0.3395 - val_accuracy: 0.8772\n",
      "Epoch 375/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8207 - val_loss: 0.3427 - val_accuracy: 0.8860\n",
      "Epoch 376/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8291 - val_loss: 0.3531 - val_accuracy: 0.8509\n",
      "Epoch 377/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8277 - val_loss: 0.3367 - val_accuracy: 0.8509\n",
      "Epoch 378/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8333 - val_loss: 0.3592 - val_accuracy: 0.8596\n",
      "Epoch 379/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4103 - accuracy: 0.8263 - val_loss: 0.3660 - val_accuracy: 0.8596\n",
      "Epoch 380/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8305 - val_loss: 0.3374 - val_accuracy: 0.8684\n",
      "Epoch 381/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8263 - val_loss: 0.4167 - val_accuracy: 0.8070\n",
      "Epoch 382/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8179 - val_loss: 0.3459 - val_accuracy: 0.8596\n",
      "Epoch 383/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4127 - accuracy: 0.8235 - val_loss: 0.3516 - val_accuracy: 0.8596\n",
      "Epoch 384/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8305 - val_loss: 0.3437 - val_accuracy: 0.8947\n",
      "Epoch 385/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.8235 - val_loss: 0.3739 - val_accuracy: 0.8509\n",
      "Epoch 386/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8333 - val_loss: 0.3939 - val_accuracy: 0.8333\n",
      "Epoch 387/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8179 - val_loss: 0.3415 - val_accuracy: 0.8684\n",
      "Epoch 388/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8291 - val_loss: 0.3426 - val_accuracy: 0.8596\n",
      "Epoch 389/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8277 - val_loss: 0.3841 - val_accuracy: 0.8246\n",
      "Epoch 390/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8137 - val_loss: 0.3388 - val_accuracy: 0.8509\n",
      "Epoch 391/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8165 - val_loss: 0.3521 - val_accuracy: 0.8596\n",
      "Epoch 392/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.8291 - val_loss: 0.3506 - val_accuracy: 0.8509\n",
      "Epoch 393/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.8235 - val_loss: 0.3419 - val_accuracy: 0.8596\n",
      "Epoch 394/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.8319 - val_loss: 0.3383 - val_accuracy: 0.8684\n",
      "Epoch 395/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8249 - val_loss: 0.3433 - val_accuracy: 0.8772\n",
      "Epoch 396/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8193 - val_loss: 0.3455 - val_accuracy: 0.8596\n",
      "Epoch 397/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8207 - val_loss: 0.3466 - val_accuracy: 0.8596\n",
      "Epoch 398/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8291 - val_loss: 0.3411 - val_accuracy: 0.8772\n",
      "Epoch 399/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4127 - accuracy: 0.8207 - val_loss: 0.3402 - val_accuracy: 0.8860\n",
      "Epoch 400/400\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.8347 - val_loss: 0.3388 - val_accuracy: 0.8684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14366e450>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Обучаем сеть\n",
    "\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=10,\n",
    "    epochs=400,\n",
    "    validation_data=(x_test,y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33876532316207886, 0.8684210777282715]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Тестируем сеть\n",
    "\n",
    "model.evaluate(x_test, y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Автоассоциативная нейронная сеть\n",
    "\n",
    "источник данных: www.kaggle.com/lava18/google-play-store-apps?select=googleplaystore.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Last Updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.041</td>\n",
       "      <td>1.590000e-07</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.039</td>\n",
       "      <td>9.670000e-07</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>5.000000e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.047</td>\n",
       "      <td>8.751000e-05</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>5.000000e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.045</td>\n",
       "      <td>2.156440e-04</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>5.000000e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>9.670000e-07</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7715</th>\n",
       "      <td>10829</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.048</td>\n",
       "      <td>4.400000e-08</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.01711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7716</th>\n",
       "      <td>10830</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.040</td>\n",
       "      <td>7.000000e-09</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>5.000000e-09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.00528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>10832</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.045</td>\n",
       "      <td>3.800000e-08</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.00491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7718</th>\n",
       "      <td>10833</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.050</td>\n",
       "      <td>4.000000e-09</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.00145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>10836</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.045</td>\n",
       "      <td>3.983070e-04</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.00126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7720 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Category  Rating       Reviews      Size      Installs  Type  \\\n",
       "0         0     0.001   0.041  1.590000e-07  0.001946  1.000000e-07  0.01   \n",
       "1         1     0.001   0.039  9.670000e-07  0.001434  5.000000e-06  0.01   \n",
       "2         2     0.001   0.047  8.751000e-05  0.000891  5.000000e-05  0.01   \n",
       "3         3     0.001   0.045  2.156440e-04  0.002560  5.000000e-04  0.01   \n",
       "4         4     0.001   0.043  9.670000e-07  0.000287  1.000000e-06  0.01   \n",
       "...     ...       ...     ...           ...       ...           ...   ...   \n",
       "7715  10829     0.004   0.048  4.400000e-08  0.000062  1.000000e-08  0.01   \n",
       "7716  10830     0.020   0.040  7.000000e-09  0.000266  5.000000e-09  0.01   \n",
       "7717  10832     0.020   0.045  3.800000e-08  0.005427  5.000000e-08  0.01   \n",
       "7718  10833     0.020   0.050  4.000000e-09  0.000369  1.000000e-09  0.01   \n",
       "7719  10836     0.018   0.045  3.983070e-04  0.001946  1.000000e-04  0.01   \n",
       "\n",
       "      Price  Content Rating  Genres  Last Updated  \n",
       "0       0.0            0.01   0.001       0.00325  \n",
       "1       0.0            0.01   0.000       0.00317  \n",
       "2       0.0            0.01   0.001       0.00119  \n",
       "3       0.0            0.02   0.001       0.00173  \n",
       "4       0.0            0.01   0.000       0.00161  \n",
       "...     ...             ...     ...           ...  \n",
       "7715    0.0            0.01   0.004       0.01711  \n",
       "7716    0.0            0.01   0.009       0.00528  \n",
       "7717    0.0            0.01   0.009       0.00491  \n",
       "7718    0.0            0.01   0.009       0.00145  \n",
       "7719    0.0            0.01   0.017       0.00126  \n",
       "\n",
       "[7720 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('googleplaystore_norm.csv', delimiter='\\t')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Last Updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.041</td>\n",
       "      <td>1.590000e-07</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.039</td>\n",
       "      <td>9.670000e-07</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>5.000000e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.047</td>\n",
       "      <td>8.751000e-05</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>5.000000e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.045</td>\n",
       "      <td>2.156440e-04</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>5.000000e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>9.670000e-07</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7715</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.048</td>\n",
       "      <td>4.400000e-08</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.01711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7716</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.040</td>\n",
       "      <td>7.000000e-09</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>5.000000e-09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.00528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.045</td>\n",
       "      <td>3.800000e-08</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.00491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7718</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.050</td>\n",
       "      <td>4.000000e-09</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.00145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.045</td>\n",
       "      <td>3.983070e-04</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.00126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7720 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category  Rating       Reviews      Size      Installs  Type  Price  \\\n",
       "0        0.001   0.041  1.590000e-07  0.001946  1.000000e-07  0.01    0.0   \n",
       "1        0.001   0.039  9.670000e-07  0.001434  5.000000e-06  0.01    0.0   \n",
       "2        0.001   0.047  8.751000e-05  0.000891  5.000000e-05  0.01    0.0   \n",
       "3        0.001   0.045  2.156440e-04  0.002560  5.000000e-04  0.01    0.0   \n",
       "4        0.001   0.043  9.670000e-07  0.000287  1.000000e-06  0.01    0.0   \n",
       "...        ...     ...           ...       ...           ...   ...    ...   \n",
       "7715     0.004   0.048  4.400000e-08  0.000062  1.000000e-08  0.01    0.0   \n",
       "7716     0.020   0.040  7.000000e-09  0.000266  5.000000e-09  0.01    0.0   \n",
       "7717     0.020   0.045  3.800000e-08  0.005427  5.000000e-08  0.01    0.0   \n",
       "7718     0.020   0.050  4.000000e-09  0.000369  1.000000e-09  0.01    0.0   \n",
       "7719     0.018   0.045  3.983070e-04  0.001946  1.000000e-04  0.01    0.0   \n",
       "\n",
       "      Content Rating  Genres  Last Updated  \n",
       "0               0.01   0.001       0.00325  \n",
       "1               0.01   0.000       0.00317  \n",
       "2               0.01   0.001       0.00119  \n",
       "3               0.02   0.001       0.00173  \n",
       "4               0.01   0.000       0.00161  \n",
       "...              ...     ...           ...  \n",
       "7715            0.01   0.004       0.01711  \n",
       "7716            0.01   0.009       0.00528  \n",
       "7717            0.01   0.009       0.00491  \n",
       "7718            0.01   0.009       0.00145  \n",
       "7719            0.01   0.017       0.00126  \n",
       "\n",
       "[7720 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=\"index\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 10), (1719, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=data[0:6000].values\n",
    "x_test=data[6001:7720].values\n",
    "\n",
    "y_train=x_train\n",
    "y_test=x_test\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 10)                60        \n",
      "=================================================================\n",
      "Total params: 115\n",
      "Trainable params: 115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "#Модель\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(10,)),\n",
    "        layers.Dense(5, activation=\"sigmoid\", name=\"layer1\"),\n",
    "        layers.Dense(10, activation=\"sigmoid\", name=\"layer2\"),\n",
    "    ],\n",
    "    name=\"AE\"\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import losses\n",
    "\n",
    "#гиперпараметры\n",
    "\n",
    "opt = keras.optimizers.SGD(learning_rate=1)\n",
    "f_loss = losses.MeanSquaredError()\n",
    "\n",
    "met = ['accuracy']\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,  \n",
    "    loss=f_loss,  \n",
    "    metrics=met, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.3658 - val_loss: 0.0126 - val_accuracy: 0.8383\n",
      "Epoch 2/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 0.8685 - val_loss: 0.0047 - val_accuracy: 0.8383\n",
      "Epoch 3/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 0.8685 - val_loss: 0.0026 - val_accuracy: 0.8383\n",
      "Epoch 4/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.8685 - val_loss: 0.0018 - val_accuracy: 0.8383\n",
      "Epoch 5/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.8685 - val_loss: 0.0013 - val_accuracy: 0.8383\n",
      "Epoch 6/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.8685 - val_loss: 0.0010 - val_accuracy: 0.8383\n",
      "Epoch 7/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 9.4247e-04 - accuracy: 0.8685 - val_loss: 8.3518e-04 - val_accuracy: 0.8383\n",
      "Epoch 8/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.8103e-04 - accuracy: 0.8685 - val_loss: 7.0119e-04 - val_accuracy: 0.8383\n",
      "Epoch 9/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.6435e-04 - accuracy: 0.8685 - val_loss: 6.0224e-04 - val_accuracy: 0.8383\n",
      "Epoch 10/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.7661e-04 - accuracy: 0.8685 - val_loss: 5.2659e-04 - val_accuracy: 0.8383\n",
      "Epoch 11/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.0856e-04 - accuracy: 0.8685 - val_loss: 4.6717e-04 - val_accuracy: 0.8383\n",
      "Epoch 12/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5447e-04 - accuracy: 0.8685 - val_loss: 4.1943e-04 - val_accuracy: 0.8383\n",
      "Epoch 13/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.1056e-04 - accuracy: 0.8685 - val_loss: 3.8036e-04 - val_accuracy: 0.8383\n",
      "Epoch 14/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.7432e-04 - accuracy: 0.8685 - val_loss: 3.4787e-04 - val_accuracy: 0.8383\n",
      "Epoch 15/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.4396e-04 - accuracy: 0.8685 - val_loss: 3.2050e-04 - val_accuracy: 0.8383\n",
      "Epoch 16/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1821e-04 - accuracy: 0.8685 - val_loss: 2.9717e-04 - val_accuracy: 0.8383\n",
      "Epoch 17/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9613e-04 - accuracy: 0.8685 - val_loss: 2.7708e-04 - val_accuracy: 0.8383\n",
      "Epoch 18/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7701e-04 - accuracy: 0.8685 - val_loss: 2.5962e-04 - val_accuracy: 0.8383\n",
      "Epoch 19/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6032e-04 - accuracy: 0.8685 - val_loss: 2.4432e-04 - val_accuracy: 0.8383\n",
      "Epoch 20/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4564e-04 - accuracy: 0.8685 - val_loss: 2.3082e-04 - val_accuracy: 0.8383\n",
      "Epoch 21/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3263e-04 - accuracy: 0.8685 - val_loss: 2.1884e-04 - val_accuracy: 0.8383\n",
      "Epoch 22/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2104e-04 - accuracy: 0.8685 - val_loss: 2.0814e-04 - val_accuracy: 0.8383\n",
      "Epoch 23/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1065e-04 - accuracy: 0.8685 - val_loss: 1.9853e-04 - val_accuracy: 0.8383\n",
      "Epoch 24/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0130e-04 - accuracy: 0.8685 - val_loss: 1.8986e-04 - val_accuracy: 0.8383\n",
      "Epoch 25/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9283e-04 - accuracy: 0.8685 - val_loss: 1.8201e-04 - val_accuracy: 0.8383\n",
      "Epoch 26/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8514e-04 - accuracy: 0.8685 - val_loss: 1.7486e-04 - val_accuracy: 0.8383\n",
      "Epoch 27/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7813e-04 - accuracy: 0.8685 - val_loss: 1.6834e-04 - val_accuracy: 0.8383\n",
      "Epoch 28/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7171e-04 - accuracy: 0.8685 - val_loss: 1.6236e-04 - val_accuracy: 0.8383\n",
      "Epoch 29/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6582e-04 - accuracy: 0.8685 - val_loss: 1.5686e-04 - val_accuracy: 0.8383\n",
      "Epoch 30/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6039e-04 - accuracy: 0.8685 - val_loss: 1.5179e-04 - val_accuracy: 0.8383\n",
      "Epoch 31/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.5537e-04 - accuracy: 0.8685 - val_loss: 1.4710e-04 - val_accuracy: 0.8383\n",
      "Epoch 32/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.5073e-04 - accuracy: 0.8685 - val_loss: 1.4276e-04 - val_accuracy: 0.8383\n",
      "Epoch 33/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.4641e-04 - accuracy: 0.8685 - val_loss: 1.3872e-04 - val_accuracy: 0.8383\n",
      "Epoch 34/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.4240e-04 - accuracy: 0.8685 - val_loss: 1.3496e-04 - val_accuracy: 0.8383\n",
      "Epoch 35/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.3865e-04 - accuracy: 0.8685 - val_loss: 1.3145e-04 - val_accuracy: 0.8383\n",
      "Epoch 36/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.3515e-04 - accuracy: 0.8685 - val_loss: 1.2817e-04 - val_accuracy: 0.8383\n",
      "Epoch 37/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.3188e-04 - accuracy: 0.8685 - val_loss: 1.2509e-04 - val_accuracy: 0.8383\n",
      "Epoch 38/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.2880e-04 - accuracy: 0.8685 - val_loss: 1.2220e-04 - val_accuracy: 0.8383\n",
      "Epoch 39/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.2591e-04 - accuracy: 0.8685 - val_loss: 1.1948e-04 - val_accuracy: 0.8383\n",
      "Epoch 40/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.2319e-04 - accuracy: 0.8685 - val_loss: 1.1692e-04 - val_accuracy: 0.8383\n",
      "Epoch 41/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.2062e-04 - accuracy: 0.8685 - val_loss: 1.1451e-04 - val_accuracy: 0.8383\n",
      "Epoch 42/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1820e-04 - accuracy: 0.8685 - val_loss: 1.1223e-04 - val_accuracy: 0.8383\n",
      "Epoch 43/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1591e-04 - accuracy: 0.8685 - val_loss: 1.1007e-04 - val_accuracy: 0.8383\n",
      "Epoch 44/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1374e-04 - accuracy: 0.8685 - val_loss: 1.0802e-04 - val_accuracy: 0.8383\n",
      "Epoch 45/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1168e-04 - accuracy: 0.8685 - val_loss: 1.0608e-04 - val_accuracy: 0.8383\n",
      "Epoch 46/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.0973e-04 - accuracy: 0.8685 - val_loss: 1.0424e-04 - val_accuracy: 0.8383\n",
      "Epoch 47/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.0788e-04 - accuracy: 0.8685 - val_loss: 1.0249e-04 - val_accuracy: 0.8383\n",
      "Epoch 48/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.0611e-04 - accuracy: 0.8685 - val_loss: 1.0082e-04 - val_accuracy: 0.8383\n",
      "Epoch 49/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.0443e-04 - accuracy: 0.8685 - val_loss: 9.9231e-05 - val_accuracy: 0.8383\n",
      "Epoch 50/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.0283e-04 - accuracy: 0.8685 - val_loss: 9.7714e-05 - val_accuracy: 0.8383\n",
      "Epoch 51/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0130e-04 - accuracy: 0.8685 - val_loss: 9.6265e-05 - val_accuracy: 0.8383\n",
      "Epoch 52/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.9835e-05 - accuracy: 0.8685 - val_loss: 9.4880e-05 - val_accuracy: 0.8383\n",
      "Epoch 53/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.8437e-05 - accuracy: 0.8685 - val_loss: 9.3555e-05 - val_accuracy: 0.8383\n",
      "Epoch 54/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.7100e-05 - accuracy: 0.8685 - val_loss: 9.2287e-05 - val_accuracy: 0.8383\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 9.5819e-05 - accuracy: 0.8685 - val_loss: 9.1070e-05 - val_accuracy: 0.8383\n",
      "Epoch 56/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.4591e-05 - accuracy: 0.8685 - val_loss: 8.9904e-05 - val_accuracy: 0.8383\n",
      "Epoch 57/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.3412e-05 - accuracy: 0.8685 - val_loss: 8.8784e-05 - val_accuracy: 0.8383\n",
      "Epoch 58/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.2281e-05 - accuracy: 0.8685 - val_loss: 8.7708e-05 - val_accuracy: 0.8383\n",
      "Epoch 59/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.1194e-05 - accuracy: 0.8685 - val_loss: 8.6673e-05 - val_accuracy: 0.8383\n",
      "Epoch 60/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.0149e-05 - accuracy: 0.8685 - val_loss: 8.5678e-05 - val_accuracy: 0.8383\n",
      "Epoch 61/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.9143e-05 - accuracy: 0.8685 - val_loss: 8.4720e-05 - val_accuracy: 0.8383\n",
      "Epoch 62/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.8175e-05 - accuracy: 0.8685 - val_loss: 8.3796e-05 - val_accuracy: 0.8383\n",
      "Epoch 63/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.7242e-05 - accuracy: 0.8685 - val_loss: 8.2906e-05 - val_accuracy: 0.8383\n",
      "Epoch 64/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.6343e-05 - accuracy: 0.8685 - val_loss: 8.2047e-05 - val_accuracy: 0.8383\n",
      "Epoch 65/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.5475e-05 - accuracy: 0.8685 - val_loss: 8.1219e-05 - val_accuracy: 0.8383\n",
      "Epoch 66/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.4638e-05 - accuracy: 0.8685 - val_loss: 8.0418e-05 - val_accuracy: 0.8383\n",
      "Epoch 67/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.3829e-05 - accuracy: 0.8685 - val_loss: 7.9644e-05 - val_accuracy: 0.8383\n",
      "Epoch 68/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.3048e-05 - accuracy: 0.8685 - val_loss: 7.8896e-05 - val_accuracy: 0.8383\n",
      "Epoch 69/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.2293e-05 - accuracy: 0.8685 - val_loss: 7.8173e-05 - val_accuracy: 0.8383\n",
      "Epoch 70/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.1562e-05 - accuracy: 0.8685 - val_loss: 7.7472e-05 - val_accuracy: 0.8383\n",
      "Epoch 71/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.0855e-05 - accuracy: 0.8685 - val_loss: 7.6794e-05 - val_accuracy: 0.8383\n",
      "Epoch 72/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.0171e-05 - accuracy: 0.8685 - val_loss: 7.6136e-05 - val_accuracy: 0.8383\n",
      "Epoch 73/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.9507e-05 - accuracy: 0.8685 - val_loss: 7.5499e-05 - val_accuracy: 0.8383\n",
      "Epoch 74/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.8865e-05 - accuracy: 0.8685 - val_loss: 7.4881e-05 - val_accuracy: 0.8383\n",
      "Epoch 75/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.8242e-05 - accuracy: 0.8685 - val_loss: 7.4282e-05 - val_accuracy: 0.8383\n",
      "Epoch 76/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.7637e-05 - accuracy: 0.8685 - val_loss: 7.3700e-05 - val_accuracy: 0.8383\n",
      "Epoch 77/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.7051e-05 - accuracy: 0.8685 - val_loss: 7.3135e-05 - val_accuracy: 0.8383\n",
      "Epoch 78/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.6481e-05 - accuracy: 0.8685 - val_loss: 7.2586e-05 - val_accuracy: 0.8383\n",
      "Epoch 79/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.5928e-05 - accuracy: 0.8685 - val_loss: 7.2052e-05 - val_accuracy: 0.8383\n",
      "Epoch 80/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.5391e-05 - accuracy: 0.8685 - val_loss: 7.1533e-05 - val_accuracy: 0.8383\n",
      "Epoch 81/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.4869e-05 - accuracy: 0.8685 - val_loss: 7.1029e-05 - val_accuracy: 0.8383\n",
      "Epoch 82/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.4361e-05 - accuracy: 0.8685 - val_loss: 7.0538e-05 - val_accuracy: 0.8383\n",
      "Epoch 83/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.3867e-05 - accuracy: 0.8685 - val_loss: 7.0060e-05 - val_accuracy: 0.8383\n",
      "Epoch 84/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.3387e-05 - accuracy: 0.8685 - val_loss: 6.9595e-05 - val_accuracy: 0.8383\n",
      "Epoch 85/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.2919e-05 - accuracy: 0.8685 - val_loss: 6.9142e-05 - val_accuracy: 0.8383\n",
      "Epoch 86/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.2464e-05 - accuracy: 0.8685 - val_loss: 6.8700e-05 - val_accuracy: 0.8383\n",
      "Epoch 87/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.2020e-05 - accuracy: 0.8685 - val_loss: 6.8270e-05 - val_accuracy: 0.8383\n",
      "Epoch 88/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.1588e-05 - accuracy: 0.8685 - val_loss: 6.7851e-05 - val_accuracy: 0.8383\n",
      "Epoch 89/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.1167e-05 - accuracy: 0.8685 - val_loss: 6.7442e-05 - val_accuracy: 0.8383\n",
      "Epoch 90/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.0756e-05 - accuracy: 0.8685 - val_loss: 6.7042e-05 - val_accuracy: 0.8383\n",
      "Epoch 91/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.0356e-05 - accuracy: 0.8685 - val_loss: 6.6653e-05 - val_accuracy: 0.8383\n",
      "Epoch 92/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.9965e-05 - accuracy: 0.8685 - val_loss: 6.6273e-05 - val_accuracy: 0.8383\n",
      "Epoch 93/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.9584e-05 - accuracy: 0.8685 - val_loss: 6.5901e-05 - val_accuracy: 0.8383\n",
      "Epoch 94/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.9212e-05 - accuracy: 0.8685 - val_loss: 6.5539e-05 - val_accuracy: 0.8383\n",
      "Epoch 95/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.8849e-05 - accuracy: 0.8685 - val_loss: 6.5185e-05 - val_accuracy: 0.8383\n",
      "Epoch 96/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.8494e-05 - accuracy: 0.8685 - val_loss: 6.4839e-05 - val_accuracy: 0.8383\n",
      "Epoch 97/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.8148e-05 - accuracy: 0.8685 - val_loss: 6.4501e-05 - val_accuracy: 0.8383\n",
      "Epoch 98/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.7810e-05 - accuracy: 0.8685 - val_loss: 6.4170e-05 - val_accuracy: 0.8383\n",
      "Epoch 99/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.7479e-05 - accuracy: 0.8685 - val_loss: 6.3847e-05 - val_accuracy: 0.8383\n",
      "Epoch 100/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.7155e-05 - accuracy: 0.8685 - val_loss: 6.3531e-05 - val_accuracy: 0.8383\n",
      "Epoch 101/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.6839e-05 - accuracy: 0.8685 - val_loss: 6.3222e-05 - val_accuracy: 0.8383\n",
      "Epoch 102/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.6530e-05 - accuracy: 0.8685 - val_loss: 6.2919e-05 - val_accuracy: 0.8383\n",
      "Epoch 103/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.6228e-05 - accuracy: 0.8685 - val_loss: 6.2623e-05 - val_accuracy: 0.8383\n",
      "Epoch 104/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.5932e-05 - accuracy: 0.8685 - val_loss: 6.2333e-05 - val_accuracy: 0.8383\n",
      "Epoch 105/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.5642e-05 - accuracy: 0.8685 - val_loss: 6.2049e-05 - val_accuracy: 0.8383\n",
      "Epoch 106/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.5359e-05 - accuracy: 0.8685 - val_loss: 6.1771e-05 - val_accuracy: 0.8383\n",
      "Epoch 107/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.5081e-05 - accuracy: 0.8685 - val_loss: 6.1498e-05 - val_accuracy: 0.8383\n",
      "Epoch 108/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.4810e-05 - accuracy: 0.8685 - val_loss: 6.1231e-05 - val_accuracy: 0.8383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.4543e-05 - accuracy: 0.8685 - val_loss: 6.0969e-05 - val_accuracy: 0.8383\n",
      "Epoch 110/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.4283e-05 - accuracy: 0.8685 - val_loss: 6.0713e-05 - val_accuracy: 0.8383\n",
      "Epoch 111/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.4027e-05 - accuracy: 0.8685 - val_loss: 6.0462e-05 - val_accuracy: 0.8383\n",
      "Epoch 112/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.3777e-05 - accuracy: 0.8685 - val_loss: 6.0215e-05 - val_accuracy: 0.8383\n",
      "Epoch 113/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.3531e-05 - accuracy: 0.8685 - val_loss: 5.9974e-05 - val_accuracy: 0.8383\n",
      "Epoch 114/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.3291e-05 - accuracy: 0.8685 - val_loss: 5.9736e-05 - val_accuracy: 0.8383\n",
      "Epoch 115/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.3055e-05 - accuracy: 0.8685 - val_loss: 5.9504e-05 - val_accuracy: 0.8383\n",
      "Epoch 116/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.2823e-05 - accuracy: 0.8685 - val_loss: 5.9276e-05 - val_accuracy: 0.8383\n",
      "Epoch 117/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.2596e-05 - accuracy: 0.8685 - val_loss: 5.9052e-05 - val_accuracy: 0.8383\n",
      "Epoch 118/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.2374e-05 - accuracy: 0.8685 - val_loss: 5.8832e-05 - val_accuracy: 0.8383\n",
      "Epoch 119/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.2155e-05 - accuracy: 0.8685 - val_loss: 5.8616e-05 - val_accuracy: 0.8383\n",
      "Epoch 120/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.1941e-05 - accuracy: 0.8685 - val_loss: 5.8404e-05 - val_accuracy: 0.8383\n",
      "Epoch 121/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.1730e-05 - accuracy: 0.8685 - val_loss: 5.8196e-05 - val_accuracy: 0.8383\n",
      "Epoch 122/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.1523e-05 - accuracy: 0.8685 - val_loss: 5.7992e-05 - val_accuracy: 0.8383\n",
      "Epoch 123/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.1320e-05 - accuracy: 0.8685 - val_loss: 5.7791e-05 - val_accuracy: 0.8383\n",
      "Epoch 124/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.1121e-05 - accuracy: 0.8685 - val_loss: 5.7594e-05 - val_accuracy: 0.8383\n",
      "Epoch 125/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.0925e-05 - accuracy: 0.8685 - val_loss: 5.7400e-05 - val_accuracy: 0.8383\n",
      "Epoch 126/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.0733e-05 - accuracy: 0.8685 - val_loss: 5.7210e-05 - val_accuracy: 0.8383\n",
      "Epoch 127/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.0544e-05 - accuracy: 0.8685 - val_loss: 5.7022e-05 - val_accuracy: 0.8383\n",
      "Epoch 128/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.0359e-05 - accuracy: 0.8685 - val_loss: 5.6838e-05 - val_accuracy: 0.8383\n",
      "Epoch 129/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.0176e-05 - accuracy: 0.8685 - val_loss: 5.6658e-05 - val_accuracy: 0.8383\n",
      "Epoch 130/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.9997e-05 - accuracy: 0.8685 - val_loss: 5.6480e-05 - val_accuracy: 0.8383\n",
      "Epoch 131/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.9821e-05 - accuracy: 0.8685 - val_loss: 5.6305e-05 - val_accuracy: 0.8383\n",
      "Epoch 132/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9647e-05 - accuracy: 0.8685 - val_loss: 5.6133e-05 - val_accuracy: 0.8383\n",
      "Epoch 133/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9477e-05 - accuracy: 0.8685 - val_loss: 5.5964e-05 - val_accuracy: 0.8383\n",
      "Epoch 134/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.9309e-05 - accuracy: 0.8685 - val_loss: 5.5797e-05 - val_accuracy: 0.8383\n",
      "Epoch 135/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9145e-05 - accuracy: 0.8685 - val_loss: 5.5634e-05 - val_accuracy: 0.8383\n",
      "Epoch 136/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.8983e-05 - accuracy: 0.8685 - val_loss: 5.5472e-05 - val_accuracy: 0.8383\n",
      "Epoch 137/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.8823e-05 - accuracy: 0.8685 - val_loss: 5.5314e-05 - val_accuracy: 0.8383\n",
      "Epoch 138/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.8666e-05 - accuracy: 0.8685 - val_loss: 5.5158e-05 - val_accuracy: 0.8383\n",
      "Epoch 139/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.8512e-05 - accuracy: 0.8685 - val_loss: 5.5004e-05 - val_accuracy: 0.8383\n",
      "Epoch 140/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.8360e-05 - accuracy: 0.8685 - val_loss: 5.4853e-05 - val_accuracy: 0.8383\n",
      "Epoch 141/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.8210e-05 - accuracy: 0.8685 - val_loss: 5.4704e-05 - val_accuracy: 0.8383\n",
      "Epoch 142/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.8063e-05 - accuracy: 0.8685 - val_loss: 5.4557e-05 - val_accuracy: 0.8383\n",
      "Epoch 143/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.7918e-05 - accuracy: 0.8685 - val_loss: 5.4413e-05 - val_accuracy: 0.8383\n",
      "Epoch 144/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.7775e-05 - accuracy: 0.8685 - val_loss: 5.4271e-05 - val_accuracy: 0.8383\n",
      "Epoch 145/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.7635e-05 - accuracy: 0.8685 - val_loss: 5.4131e-05 - val_accuracy: 0.8383\n",
      "Epoch 146/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.7496e-05 - accuracy: 0.8685 - val_loss: 5.3993e-05 - val_accuracy: 0.8383\n",
      "Epoch 147/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.7360e-05 - accuracy: 0.8685 - val_loss: 5.3857e-05 - val_accuracy: 0.8383\n",
      "Epoch 148/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.7226e-05 - accuracy: 0.8685 - val_loss: 5.3723e-05 - val_accuracy: 0.8383\n",
      "Epoch 149/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.7093e-05 - accuracy: 0.8685 - val_loss: 5.3591e-05 - val_accuracy: 0.8383\n",
      "Epoch 150/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.6963e-05 - accuracy: 0.8685 - val_loss: 5.3461e-05 - val_accuracy: 0.8383\n",
      "Epoch 151/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.6835e-05 - accuracy: 0.8685 - val_loss: 5.3333e-05 - val_accuracy: 0.8383\n",
      "Epoch 152/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.6708e-05 - accuracy: 0.8685 - val_loss: 5.3207e-05 - val_accuracy: 0.8383\n",
      "Epoch 153/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.6583e-05 - accuracy: 0.8685 - val_loss: 5.3083e-05 - val_accuracy: 0.8383\n",
      "Epoch 154/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.6460e-05 - accuracy: 0.8685 - val_loss: 5.2960e-05 - val_accuracy: 0.8383\n",
      "Epoch 155/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.6339e-05 - accuracy: 0.8685 - val_loss: 5.2839e-05 - val_accuracy: 0.8383\n",
      "Epoch 156/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.6220e-05 - accuracy: 0.8685 - val_loss: 5.2720e-05 - val_accuracy: 0.8383\n",
      "Epoch 157/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.6102e-05 - accuracy: 0.8685 - val_loss: 5.2602e-05 - val_accuracy: 0.8383\n",
      "Epoch 158/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.5986e-05 - accuracy: 0.8685 - val_loss: 5.2486e-05 - val_accuracy: 0.8383\n",
      "Epoch 159/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.5871e-05 - accuracy: 0.8685 - val_loss: 5.2372e-05 - val_accuracy: 0.8383\n",
      "Epoch 160/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.5758e-05 - accuracy: 0.8685 - val_loss: 5.2259e-05 - val_accuracy: 0.8383\n",
      "Epoch 161/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.5647e-05 - accuracy: 0.8685 - val_loss: 5.2147e-05 - val_accuracy: 0.8383\n",
      "Epoch 162/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 5.5537e-05 - accuracy: 0.8685 - val_loss: 5.2038e-05 - val_accuracy: 0.8383\n",
      "Epoch 163/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.5429e-05 - accuracy: 0.8685 - val_loss: 5.1929e-05 - val_accuracy: 0.8383\n",
      "Epoch 164/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.5322e-05 - accuracy: 0.8685 - val_loss: 5.1822e-05 - val_accuracy: 0.8383\n",
      "Epoch 165/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.5217e-05 - accuracy: 0.8685 - val_loss: 5.1717e-05 - val_accuracy: 0.8383\n",
      "Epoch 166/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.5112e-05 - accuracy: 0.8685 - val_loss: 5.1613e-05 - val_accuracy: 0.8383\n",
      "Epoch 167/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.5010e-05 - accuracy: 0.8685 - val_loss: 5.1510e-05 - val_accuracy: 0.8383\n",
      "Epoch 168/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.4908e-05 - accuracy: 0.8685 - val_loss: 5.1409e-05 - val_accuracy: 0.8383\n",
      "Epoch 169/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.4808e-05 - accuracy: 0.8685 - val_loss: 5.1309e-05 - val_accuracy: 0.8383\n",
      "Epoch 170/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.4710e-05 - accuracy: 0.8685 - val_loss: 5.1210e-05 - val_accuracy: 0.8383\n",
      "Epoch 171/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.4612e-05 - accuracy: 0.8685 - val_loss: 5.1113e-05 - val_accuracy: 0.8383\n",
      "Epoch 172/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.4516e-05 - accuracy: 0.8685 - val_loss: 5.1016e-05 - val_accuracy: 0.8383\n",
      "Epoch 173/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.4421e-05 - accuracy: 0.8685 - val_loss: 5.0921e-05 - val_accuracy: 0.8383\n",
      "Epoch 174/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.4327e-05 - accuracy: 0.8685 - val_loss: 5.0827e-05 - val_accuracy: 0.8383\n",
      "Epoch 175/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.4235e-05 - accuracy: 0.8685 - val_loss: 5.0735e-05 - val_accuracy: 0.8383\n",
      "Epoch 176/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.4143e-05 - accuracy: 0.8685 - val_loss: 5.0643e-05 - val_accuracy: 0.8383\n",
      "Epoch 177/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.4053e-05 - accuracy: 0.8685 - val_loss: 5.0553e-05 - val_accuracy: 0.8383\n",
      "Epoch 178/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.3964e-05 - accuracy: 0.8685 - val_loss: 5.0464e-05 - val_accuracy: 0.8383\n",
      "Epoch 179/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.3876e-05 - accuracy: 0.8685 - val_loss: 5.0375e-05 - val_accuracy: 0.8383\n",
      "Epoch 180/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.3789e-05 - accuracy: 0.8685 - val_loss: 5.0288e-05 - val_accuracy: 0.8383\n",
      "Epoch 181/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.3703e-05 - accuracy: 0.8685 - val_loss: 5.0202e-05 - val_accuracy: 0.8383\n",
      "Epoch 182/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.3618e-05 - accuracy: 0.8685 - val_loss: 5.0117e-05 - val_accuracy: 0.8383\n",
      "Epoch 183/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.3534e-05 - accuracy: 0.8685 - val_loss: 5.0033e-05 - val_accuracy: 0.8383\n",
      "Epoch 184/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.3451e-05 - accuracy: 0.8685 - val_loss: 4.9950e-05 - val_accuracy: 0.8383\n",
      "Epoch 185/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.3369e-05 - accuracy: 0.8685 - val_loss: 4.9868e-05 - val_accuracy: 0.8383\n",
      "Epoch 186/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.3288e-05 - accuracy: 0.8685 - val_loss: 4.9787e-05 - val_accuracy: 0.8383\n",
      "Epoch 187/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.3208e-05 - accuracy: 0.8685 - val_loss: 4.9707e-05 - val_accuracy: 0.8383\n",
      "Epoch 188/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.3129e-05 - accuracy: 0.8685 - val_loss: 4.9628e-05 - val_accuracy: 0.8383\n",
      "Epoch 189/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.3051e-05 - accuracy: 0.8685 - val_loss: 4.9550e-05 - val_accuracy: 0.8383\n",
      "Epoch 190/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2974e-05 - accuracy: 0.8685 - val_loss: 4.9472e-05 - val_accuracy: 0.8383\n",
      "Epoch 191/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2898e-05 - accuracy: 0.8685 - val_loss: 4.9396e-05 - val_accuracy: 0.8383\n",
      "Epoch 192/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2822e-05 - accuracy: 0.8685 - val_loss: 4.9321e-05 - val_accuracy: 0.8383\n",
      "Epoch 193/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2748e-05 - accuracy: 0.8685 - val_loss: 4.9246e-05 - val_accuracy: 0.8383\n",
      "Epoch 194/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2674e-05 - accuracy: 0.8685 - val_loss: 4.9172e-05 - val_accuracy: 0.8383\n",
      "Epoch 195/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2601e-05 - accuracy: 0.8685 - val_loss: 4.9099e-05 - val_accuracy: 0.8383\n",
      "Epoch 196/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2529e-05 - accuracy: 0.8685 - val_loss: 4.9027e-05 - val_accuracy: 0.8383\n",
      "Epoch 197/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2458e-05 - accuracy: 0.8685 - val_loss: 4.8956e-05 - val_accuracy: 0.8383\n",
      "Epoch 198/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2387e-05 - accuracy: 0.8685 - val_loss: 4.8885e-05 - val_accuracy: 0.8383\n",
      "Epoch 199/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2318e-05 - accuracy: 0.8685 - val_loss: 4.8815e-05 - val_accuracy: 0.8383\n",
      "Epoch 200/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2249e-05 - accuracy: 0.8685 - val_loss: 4.8746e-05 - val_accuracy: 0.8383\n",
      "Epoch 201/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2180e-05 - accuracy: 0.8685 - val_loss: 4.8678e-05 - val_accuracy: 0.8383\n",
      "Epoch 202/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2113e-05 - accuracy: 0.8685 - val_loss: 4.8611e-05 - val_accuracy: 0.8383\n",
      "Epoch 203/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.2046e-05 - accuracy: 0.8685 - val_loss: 4.8544e-05 - val_accuracy: 0.8383\n",
      "Epoch 204/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1980e-05 - accuracy: 0.8685 - val_loss: 4.8478e-05 - val_accuracy: 0.8383\n",
      "Epoch 205/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1915e-05 - accuracy: 0.8685 - val_loss: 4.8412e-05 - val_accuracy: 0.8383\n",
      "Epoch 206/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1850e-05 - accuracy: 0.8685 - val_loss: 4.8348e-05 - val_accuracy: 0.8383\n",
      "Epoch 207/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1787e-05 - accuracy: 0.8685 - val_loss: 4.8284e-05 - val_accuracy: 0.8383\n",
      "Epoch 208/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1723e-05 - accuracy: 0.8685 - val_loss: 4.8220e-05 - val_accuracy: 0.8383\n",
      "Epoch 209/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.1661e-05 - accuracy: 0.8685 - val_loss: 4.8158e-05 - val_accuracy: 0.8383\n",
      "Epoch 210/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.1599e-05 - accuracy: 0.8685 - val_loss: 4.8096e-05 - val_accuracy: 0.8383\n",
      "Epoch 211/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1538e-05 - accuracy: 0.8685 - val_loss: 4.8034e-05 - val_accuracy: 0.8383\n",
      "Epoch 212/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1477e-05 - accuracy: 0.8685 - val_loss: 4.7974e-05 - val_accuracy: 0.8383\n",
      "Epoch 213/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1417e-05 - accuracy: 0.8685 - val_loss: 4.7914e-05 - val_accuracy: 0.8383\n",
      "Epoch 214/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1358e-05 - accuracy: 0.8685 - val_loss: 4.7855e-05 - val_accuracy: 0.8383\n",
      "Epoch 215/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1299e-05 - accuracy: 0.8685 - val_loss: 4.7796e-05 - val_accuracy: 0.8383\n",
      "Epoch 216/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1241e-05 - accuracy: 0.8685 - val_loss: 4.7737e-05 - val_accuracy: 0.8383\n",
      "Epoch 217/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1183e-05 - accuracy: 0.8685 - val_loss: 4.7680e-05 - val_accuracy: 0.8383\n",
      "Epoch 218/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1126e-05 - accuracy: 0.8685 - val_loss: 4.7623e-05 - val_accuracy: 0.8383\n",
      "Epoch 219/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.1070e-05 - accuracy: 0.8685 - val_loss: 4.7566e-05 - val_accuracy: 0.8383\n",
      "Epoch 220/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1014e-05 - accuracy: 0.8685 - val_loss: 4.7510e-05 - val_accuracy: 0.8383\n",
      "Epoch 221/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0958e-05 - accuracy: 0.8685 - val_loss: 4.7455e-05 - val_accuracy: 0.8383\n",
      "Epoch 222/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0904e-05 - accuracy: 0.8685 - val_loss: 4.7400e-05 - val_accuracy: 0.8383\n",
      "Epoch 223/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0849e-05 - accuracy: 0.8685 - val_loss: 4.7346e-05 - val_accuracy: 0.8383\n",
      "Epoch 224/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0796e-05 - accuracy: 0.8685 - val_loss: 4.7292e-05 - val_accuracy: 0.8383\n",
      "Epoch 225/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0742e-05 - accuracy: 0.8685 - val_loss: 4.7239e-05 - val_accuracy: 0.8383\n",
      "Epoch 226/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0690e-05 - accuracy: 0.8685 - val_loss: 4.7186e-05 - val_accuracy: 0.8383\n",
      "Epoch 227/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0638e-05 - accuracy: 0.8685 - val_loss: 4.7134e-05 - val_accuracy: 0.8383\n",
      "Epoch 228/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0586e-05 - accuracy: 0.8685 - val_loss: 4.7083e-05 - val_accuracy: 0.8383\n",
      "Epoch 229/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0535e-05 - accuracy: 0.8685 - val_loss: 4.7031e-05 - val_accuracy: 0.8383\n",
      "Epoch 230/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0484e-05 - accuracy: 0.8685 - val_loss: 4.6981e-05 - val_accuracy: 0.8383\n",
      "Epoch 231/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0434e-05 - accuracy: 0.8685 - val_loss: 4.6931e-05 - val_accuracy: 0.8383\n",
      "Epoch 232/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0384e-05 - accuracy: 0.8685 - val_loss: 4.6881e-05 - val_accuracy: 0.8383\n",
      "Epoch 233/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0335e-05 - accuracy: 0.8685 - val_loss: 4.6832e-05 - val_accuracy: 0.8383\n",
      "Epoch 234/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0286e-05 - accuracy: 0.8685 - val_loss: 4.6783e-05 - val_accuracy: 0.8383\n",
      "Epoch 235/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0238e-05 - accuracy: 0.8685 - val_loss: 4.6735e-05 - val_accuracy: 0.8383\n",
      "Epoch 236/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0190e-05 - accuracy: 0.8685 - val_loss: 4.6687e-05 - val_accuracy: 0.8383\n",
      "Epoch 237/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0142e-05 - accuracy: 0.8685 - val_loss: 4.6640e-05 - val_accuracy: 0.8383\n",
      "Epoch 238/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0095e-05 - accuracy: 0.8685 - val_loss: 4.6593e-05 - val_accuracy: 0.8383\n",
      "Epoch 239/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0049e-05 - accuracy: 0.8685 - val_loss: 4.6546e-05 - val_accuracy: 0.8383\n",
      "Epoch 240/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0003e-05 - accuracy: 0.8685 - val_loss: 4.6500e-05 - val_accuracy: 0.8383\n",
      "Epoch 241/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9957e-05 - accuracy: 0.8685 - val_loss: 4.6454e-05 - val_accuracy: 0.8383\n",
      "Epoch 242/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9912e-05 - accuracy: 0.8685 - val_loss: 4.6409e-05 - val_accuracy: 0.8383\n",
      "Epoch 243/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9867e-05 - accuracy: 0.8685 - val_loss: 4.6364e-05 - val_accuracy: 0.8383\n",
      "Epoch 244/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9822e-05 - accuracy: 0.8685 - val_loss: 4.6320e-05 - val_accuracy: 0.8383\n",
      "Epoch 245/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9778e-05 - accuracy: 0.8685 - val_loss: 4.6276e-05 - val_accuracy: 0.8383\n",
      "Epoch 246/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9734e-05 - accuracy: 0.8685 - val_loss: 4.6232e-05 - val_accuracy: 0.8383\n",
      "Epoch 247/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9691e-05 - accuracy: 0.8685 - val_loss: 4.6189e-05 - val_accuracy: 0.8383\n",
      "Epoch 248/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9648e-05 - accuracy: 0.8685 - val_loss: 4.6146e-05 - val_accuracy: 0.8383\n",
      "Epoch 249/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9606e-05 - accuracy: 0.8685 - val_loss: 4.6103e-05 - val_accuracy: 0.8383\n",
      "Epoch 250/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9563e-05 - accuracy: 0.8685 - val_loss: 4.6061e-05 - val_accuracy: 0.8383\n",
      "Epoch 251/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9521e-05 - accuracy: 0.8685 - val_loss: 4.6019e-05 - val_accuracy: 0.8383\n",
      "Epoch 252/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9480e-05 - accuracy: 0.8685 - val_loss: 4.5978e-05 - val_accuracy: 0.8383\n",
      "Epoch 253/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.9439e-05 - accuracy: 0.8685 - val_loss: 4.5937e-05 - val_accuracy: 0.8383\n",
      "Epoch 254/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9398e-05 - accuracy: 0.8685 - val_loss: 4.5896e-05 - val_accuracy: 0.8383\n",
      "Epoch 255/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9358e-05 - accuracy: 0.8685 - val_loss: 4.5856e-05 - val_accuracy: 0.8383\n",
      "Epoch 256/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9318e-05 - accuracy: 0.8685 - val_loss: 4.5816e-05 - val_accuracy: 0.8383\n",
      "Epoch 257/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9278e-05 - accuracy: 0.8685 - val_loss: 4.5776e-05 - val_accuracy: 0.8383\n",
      "Epoch 258/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9239e-05 - accuracy: 0.8685 - val_loss: 4.5737e-05 - val_accuracy: 0.8383\n",
      "Epoch 259/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9199e-05 - accuracy: 0.8685 - val_loss: 4.5698e-05 - val_accuracy: 0.8383\n",
      "Epoch 260/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9161e-05 - accuracy: 0.8685 - val_loss: 4.5660e-05 - val_accuracy: 0.8383\n",
      "Epoch 261/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9122e-05 - accuracy: 0.8685 - val_loss: 4.5621e-05 - val_accuracy: 0.8383\n",
      "Epoch 262/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9084e-05 - accuracy: 0.8685 - val_loss: 4.5584e-05 - val_accuracy: 0.8383\n",
      "Epoch 263/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9047e-05 - accuracy: 0.8685 - val_loss: 4.5546e-05 - val_accuracy: 0.8383\n",
      "Epoch 264/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9009e-05 - accuracy: 0.8685 - val_loss: 4.5509e-05 - val_accuracy: 0.8383\n",
      "Epoch 265/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8972e-05 - accuracy: 0.8685 - val_loss: 4.5472e-05 - val_accuracy: 0.8383\n",
      "Epoch 266/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8935e-05 - accuracy: 0.8685 - val_loss: 4.5435e-05 - val_accuracy: 0.8383\n",
      "Epoch 267/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8899e-05 - accuracy: 0.8685 - val_loss: 4.5398e-05 - val_accuracy: 0.8383\n",
      "Epoch 268/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8862e-05 - accuracy: 0.8685 - val_loss: 4.5362e-05 - val_accuracy: 0.8383\n",
      "Epoch 269/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8826e-05 - accuracy: 0.8685 - val_loss: 4.5327e-05 - val_accuracy: 0.8383\n",
      "Epoch 270/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8791e-05 - accuracy: 0.8685 - val_loss: 4.5291e-05 - val_accuracy: 0.8383\n",
      "Epoch 271/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8755e-05 - accuracy: 0.8685 - val_loss: 4.5256e-05 - val_accuracy: 0.8383\n",
      "Epoch 272/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8720e-05 - accuracy: 0.8685 - val_loss: 4.5221e-05 - val_accuracy: 0.8383\n",
      "Epoch 273/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8686e-05 - accuracy: 0.8685 - val_loss: 4.5187e-05 - val_accuracy: 0.8383\n",
      "Epoch 274/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8651e-05 - accuracy: 0.8685 - val_loss: 4.5152e-05 - val_accuracy: 0.8383\n",
      "Epoch 275/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8617e-05 - accuracy: 0.8685 - val_loss: 4.5118e-05 - val_accuracy: 0.8383\n",
      "Epoch 276/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8583e-05 - accuracy: 0.8685 - val_loss: 4.5084e-05 - val_accuracy: 0.8383\n",
      "Epoch 277/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8549e-05 - accuracy: 0.8685 - val_loss: 4.5051e-05 - val_accuracy: 0.8383\n",
      "Epoch 278/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8516e-05 - accuracy: 0.8685 - val_loss: 4.5017e-05 - val_accuracy: 0.8383\n",
      "Epoch 279/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8482e-05 - accuracy: 0.8685 - val_loss: 4.4984e-05 - val_accuracy: 0.8383\n",
      "Epoch 280/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8449e-05 - accuracy: 0.8685 - val_loss: 4.4952e-05 - val_accuracy: 0.8383\n",
      "Epoch 281/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8417e-05 - accuracy: 0.8685 - val_loss: 4.4919e-05 - val_accuracy: 0.8383\n",
      "Epoch 282/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8384e-05 - accuracy: 0.8685 - val_loss: 4.4887e-05 - val_accuracy: 0.8383\n",
      "Epoch 283/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.8352e-05 - accuracy: 0.8685 - val_loss: 4.4855e-05 - val_accuracy: 0.8383\n",
      "Epoch 284/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.8320e-05 - accuracy: 0.8685 - val_loss: 4.4823e-05 - val_accuracy: 0.8383\n",
      "Epoch 285/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.8289e-05 - accuracy: 0.8685 - val_loss: 4.4792e-05 - val_accuracy: 0.8383\n",
      "Epoch 286/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.8257e-05 - accuracy: 0.8685 - val_loss: 4.4760e-05 - val_accuracy: 0.8383\n",
      "Epoch 287/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8226e-05 - accuracy: 0.8685 - val_loss: 4.4729e-05 - val_accuracy: 0.8383\n",
      "Epoch 288/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.8195e-05 - accuracy: 0.8685 - val_loss: 4.4699e-05 - val_accuracy: 0.8383\n",
      "Epoch 289/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8164e-05 - accuracy: 0.8685 - val_loss: 4.4668e-05 - val_accuracy: 0.8383\n",
      "Epoch 290/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8134e-05 - accuracy: 0.8685 - val_loss: 4.4638e-05 - val_accuracy: 0.8383\n",
      "Epoch 291/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8104e-05 - accuracy: 0.8685 - val_loss: 4.4608e-05 - val_accuracy: 0.8383\n",
      "Epoch 292/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8074e-05 - accuracy: 0.8685 - val_loss: 4.4578e-05 - val_accuracy: 0.8383\n",
      "Epoch 293/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8044e-05 - accuracy: 0.8685 - val_loss: 4.4548e-05 - val_accuracy: 0.8383\n",
      "Epoch 294/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8014e-05 - accuracy: 0.8685 - val_loss: 4.4519e-05 - val_accuracy: 0.8383\n",
      "Epoch 295/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.7985e-05 - accuracy: 0.8685 - val_loss: 4.4490e-05 - val_accuracy: 0.8383\n",
      "Epoch 296/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7956e-05 - accuracy: 0.8685 - val_loss: 4.4461e-05 - val_accuracy: 0.8383\n",
      "Epoch 297/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.7927e-05 - accuracy: 0.8685 - val_loss: 4.4432e-05 - val_accuracy: 0.8383\n",
      "Epoch 298/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7898e-05 - accuracy: 0.8685 - val_loss: 4.4404e-05 - val_accuracy: 0.8383\n",
      "Epoch 299/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7869e-05 - accuracy: 0.8685 - val_loss: 4.4375e-05 - val_accuracy: 0.8383\n",
      "Epoch 300/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7841e-05 - accuracy: 0.8685 - val_loss: 4.4347e-05 - val_accuracy: 0.8383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1498e9390>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Обучаем сеть\n",
    "\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=60,\n",
    "    epochs=300,\n",
    "    validation_data=(x_test,y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.48246342, -0.01163077,  0.06639706, -0.53769386,  0.21986209],\n",
       "        [-0.08979593, -0.39405596,  0.14585276, -0.38077375, -0.07969332],\n",
       "        [ 0.24623291, -0.6254914 ,  0.24402496, -0.3701828 , -0.09953714],\n",
       "        [ 0.27340052, -0.51413894, -0.23216538, -0.31903383,  0.07237355],\n",
       "        [-0.5158613 ,  0.38172317, -0.41681987, -0.13509382, -0.5626315 ],\n",
       "        [-0.61272573,  0.12966931, -0.40372652, -0.5052863 , -0.02855318],\n",
       "        [-0.4806758 , -0.02174802,  0.4478047 , -0.60643727,  0.28566068],\n",
       "        [ 0.50025344,  0.5956608 , -0.15397045,  0.43286255, -0.31263596],\n",
       "        [ 0.12387858,  0.20797725,  0.5429636 ,  0.59675586,  0.6356946 ],\n",
       "        [-0.5840634 , -0.15797918, -0.17009044,  0.03325456, -0.2898344 ]],\n",
       "       dtype=float32),\n",
       " array([0.5433009 , 1.3772937 , 0.99055284, 0.7446707 , 1.8037246 ],\n",
       "       dtype=float32),\n",
       " array([[-0.43001276, -0.65709263, -0.55436695, -0.5156844 , -0.8434499 ,\n",
       "         -0.4284244 , -1.0841386 , -0.16644141, -0.5086835 , -0.37815657],\n",
       "        [-0.1656647 , -0.7274508 , -1.5267972 , -1.5546211 , -1.1437224 ,\n",
       "         -1.1993207 , -0.58146465, -0.5711355 , -0.8302728 , -0.76095307],\n",
       "        [-0.80611706, -0.22761337, -1.067694  , -0.5110146 , -0.85686016,\n",
       "         -0.6743369 , -0.69576406, -0.83766454, -1.0540844 , -0.91807514],\n",
       "        [-0.763118  , -0.26123893, -0.47622046, -0.5232269 , -0.52150214,\n",
       "         -1.031225  , -1.0045428 , -1.0963762 , -0.31178278, -0.55695647],\n",
       "        [-1.2517661 , -0.75914323, -0.80709714, -1.1007057 , -1.3915877 ,\n",
       "         -1.1453912 , -1.5930178 , -1.2733754 , -1.1420703 , -1.607705  ]],\n",
       "       dtype=float32),\n",
       " array([-1.35915   , -1.1398331 , -2.0109503 , -1.9778295 , -1.7780395 ,\n",
       "        -1.2515113 , -1.6944736 , -1.2866604 , -0.82081944, -1.8356962 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=model.get_weights()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x148c39050>,\n",
       " <matplotlib.lines.Line2D at 0x148b03c90>,\n",
       " <matplotlib.lines.Line2D at 0x14a80e090>,\n",
       " <matplotlib.lines.Line2D at 0x14a80e150>,\n",
       " <matplotlib.lines.Line2D at 0x14a80e210>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
